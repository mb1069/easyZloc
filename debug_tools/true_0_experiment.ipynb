{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2913a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Reading img...\n",
      "Loading /home/miguel/Projects/uni/data/smlm_3d/20220729_nup/28_07_2022_sample/prime95b/A2/FOV3/storm_1/storm_1_MMStack_Default_1_cropped.ome.tif\n",
      "Loading /home/miguel/Projects/uni/data/smlm_3d/20220729_nup/28_07_2022_sample/prime95b/A2/FOV3/storm_1/storm_1_MMStack_Default_1_cropped.csv\n",
      "425133 emitters before filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 126/365224 [00:00<04:50, 1258.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365224 emitters after borders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365224/365224 [03:38<00:00, 1671.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering emitters...\n",
      "Initial: N images 365224 - DF: (365224, 10)\n",
      "Final: images 1729 - DF: (1729, 12)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from config.datasets import dataset_configs\n",
    "from data.datasets import StormDataset, ExperimentalDataSet\n",
    "\n",
    "dataset ='20220729_nup'\n",
    "\n",
    "cfg = dataset_configs[dataset]['fov3_0']\n",
    "ds = StormDataset(cfg, normalize_psf=True, lazy=True)\n",
    "ds.csv_data = ds.csv_data[ds.csv_data['sigma [nm]'] > 20]\n",
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeefaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data.visualise import scatter_3d, scatter_yz, show_psf_axial, plot_with_sphere, grid_psfs\n",
    "from data.datasets import ExperimentalDataSet, TrainingDataSet\n",
    "\n",
    "from config.datasets import dataset_configs\n",
    "from data.estimate_offset import remove_bg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "\n",
    "cfgs = dataset_configs['20220425_Miguel']\n",
    "\n",
    "psfs = []\n",
    "for cfg in cfgs:\n",
    "    if cfg != 'training_20nm':\n",
    "        continue\n",
    "    cfg = cfgs['training_20nm']\n",
    "    ds = TrainingDataSet(cfg, fit_plane_z=False, transform_data=False, z_range=10000, lazy=True, split_data=False, add_noise=False, filter_emitters_proximity=True)\n",
    "    ds.prepare_debug()\n",
    "    for i in range(ds.csv_data.shape[0]):\n",
    "        psfs.append(ds.debug_emitter(i, 10000)[0])\n",
    "        print(len(psfs))\n",
    "    del ds\n",
    "\n",
    "psfs = np.array(psfs)\n",
    "print(psfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32689c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyotf.otf import HanserPSF, apply_aberration, apply_named_aberration\n",
    "\n",
    "kwargs = dict(\n",
    "    wl=647,\n",
    "    na=1.3,\n",
    "    ni=1.51,\n",
    "    res=106,\n",
    "    zres=10,\n",
    "    size=32,\n",
    "    zsize=200,\n",
    "    vec_corr=\"none\",\n",
    "    condition=\"none\",\n",
    ")\n",
    "psf = HanserPSF(**kwargs)\n",
    "psf = apply_aberration(psf, np.array([0, 0, 0, 0, 0]), np.array([0, 0, 0, 0, 1]))\n",
    "\n",
    "blank_psf = psf.PSFi\n",
    "\n",
    "print(np.argmax(blank_psf.max(axis=(1,2))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63226f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from experiments.noise.noise_psf import generate_noisy_psf\n",
    "fake_psfs = []\n",
    "\n",
    "blank_psf = blank_psf / blank_psf.max()\n",
    "\n",
    "snrs = []\n",
    "n_psfs = 100\n",
    "for _ in range(n_psfs):\n",
    "    nsr = np.random.uniform(0, 0.25)\n",
    "    fake_psf = generate_noisy_psf(blank_psf, nsr)\n",
    "    fake_psfs.append(fake_psf)\n",
    "    snr =  fake_psf.max() / np.median(fake_psf)\n",
    "    snrs.append(snr)\n",
    "    \n",
    "\n",
    "psfs = np.array(fake_psfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3edbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data.estimate_offset import norm_zero_one\n",
    "\n",
    "def remove_bg(img):\n",
    "    img = norm_zero_one(img)\n",
    "    if img.ndim == 3:\n",
    "        bg_level = img.max(axis=(1,2)).min()\n",
    "    else:\n",
    "        bg_level = img.min()\n",
    "    mult = 1.2\n",
    "    img = img - (bg_level * mult)\n",
    "    img[img<0] = 0\n",
    "    img = norm_zero_one(img)\n",
    "    return img\n",
    "psfs = np.array([remove_bg(psf) for psf in psfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527297b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from data.estimate_offset import get_sharpness\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "sharpness = np.array([get_sharpness(psf) for psf in psfs])\n",
    "n_psfs = psfs.shape[0]\n",
    "res = []\n",
    "\n",
    "sub_x = np.linspace(0, psfs.shape[1], 1000, endpoint=True)\n",
    "\n",
    "    \n",
    "def fit_cubic_spline(y, x, sub_x, s=0.05):\n",
    "    cs = UnivariateSpline(x, list(y), k=3, s=s)\n",
    "    print(cs(x))\n",
    "    # TODO potentially use this to exclude beads?\n",
    "    # evaluate sum of squared second derivative as a measurement of curve smoothness\n",
    "    smoothness = sum(np.power(cs(sub_x, 2), 2))\n",
    "\n",
    "    if smoothness > 5:\n",
    "        plt.plot(x, norm_zero_one(cs(x)))\n",
    "        raise EnvironmentError('Failed to fit bead accurately.')\n",
    "\n",
    "    return cs(sub_x)\n",
    "\n",
    "\n",
    "for std in [5, 10, 15, 20, 25, 30, 35, 40]:\n",
    "    \n",
    "    for i in range(n_psfs):\n",
    "        for window in range(5, sharpness.shape[1]//2, 5):\n",
    "            smooth_data = pd.Series(sharpness[i]).rolling(window=window, win_type='gaussian', center=True).mean(std=std)\n",
    "            hr_smooth_data = fit_cubic_spline(smooth_data, smooth_data.index, sub_x)\n",
    "            \n",
    "            plt.plot(smooth_data, label=str(window))\n",
    "#             plt.plot(sharpness[i], label='raw')\n",
    "            plt.plot(hr_smooth_data+1, label='high_res_smooth')\n",
    "            print(hr_smooth_data)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            res.append((window, np.argmax(smooth_data), snrs[i], std))\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "#     if i2 == 95 and std > 5:\n",
    "#         show_psf_axial(psfs[i])\n",
    "    #     break\n",
    "    #     snr = fake_psfs[i].max() / np.median(fake_psfs[i])\n",
    "    #     plt.title(f'{snr} - {1/nsrs[i]}')\n",
    "    #     show_psf_axial(fake_psfs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c301fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, snr, std = zip(*res)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame.from_dict({'smooth': x, 'pred': y, 'snr': snr, 'std': std})\n",
    "\n",
    "\n",
    "print('a', df)\n",
    "# df = df[df['snr']> 10] \n",
    "print('b', df.shape)\n",
    "\n",
    "sns.scatterplot(data=df, x='smooth', y='pred', hue='snr')\n",
    "plt.show()\n",
    "\n",
    "means = df.groupby(['smooth', 'std']).std()\n",
    "print(means['pred'].idxmin())\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b56ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
