 3/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
 3/2: 60**2
 4/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
 4/2: tuple(400 * len(col_names),)
 4/3: tuple((400,) * 3)
 4/4: (400,) * 3
 4/5: import torch
 4/6: torch.cuda.is_available()
 5/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
 5/2: import torch
 5/3: torch.zeros((4,3)).size()
 6/1: import tensorflow as tf
 6/2:
# Create an SGD optimiser

sgd = tf.keras.optimizers.SGD()

print(sgd.lr)  # Default learning rate
 6/3:
# Create an SGD optimiser with momentum

sgd_with_momentum = tf.keras.optimizers.SGD(momentum=0.9)

print(sgd_with_momentum.lr)
print(sgd_with_momentum.momentum)
 6/4:
# Create an SGD optimiser with momentum

sgd_with_momentum = tf.keras.optimizers.SGD(momentum=0.9, nesterov=True)

print(sgd_with_momentum.momentum)
print(sgd_with_momentum.nesterov)
 6/5:
# Create an Adagrad optimiser

adagrad = tf.keras.optimizers.Adagrad(
    learning_rate=0.001, initial_accumulator_value=0.1, epsilon=1e-07,
)
 6/6:
# Create an RMSprop optimiser

rmsprop = tf.keras.optimizers.RMSprop(
    learning_rate=0.001, rho=0.9, epsilon=1e-07
)
 6/7:
# Create an RMSprop optimiser with momentum

rmsprop_with_momentum = tf.keras.optimizers.RMSprop(momentum=0.9)
 6/8:
# Create an Adam optimiser

adam = tf.keras.optimizers.Adam()

print(adam.lr)
print(adam.beta_1)
print(adam.beta_2)
print(adam.epsilon)
 6/9:
def beale(x, y):
    return (1.5 - x + x * y)**2 + (2.25 - x + x * (y**2))**2 + (2.625 - x + x * (y**3))**2

def grad_beale(x, y):
    ddx = 2*(1.5 - x + x * y)*(y - 1) + 2*(2.25 - x + x * (y**2))*((y**2) - 1) + 2*(2.625 - x + x * (y**3))*((y**3)-1)
    ddy = 2*(1.5 - x + x * y)*(x) + 2*(2.25 - x + x * (y**2))*(2*y*x) + 2*(2.625 - x + x * (y**3))*(3*(y**2)*x)
    return [ddx, ddy]
6/10:
from IPython import display
import matplotlib.pyplot as plt
import numpy as np

x_init = tf.random.normal(())
y_init = tf.random.normal(())

test_fn = beale
grad_fn = grad_beale

X, Y = np.meshgrid(np.linspace(-4, 4, 100), np.linspace(-4, 4, 100))
Z = test_fn(X, Y)
levels = np.exp(np.linspace(0, 10, 25)) - 1
plt.figure(figsize=(13, 8))
plt.contour(X, Y, Z, levels, alpha=0.6, cmap='viridis')
plt.colorbar()
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x_init.numpy(), y_init.numpy())
plt.scatter(3, 0.5, marker='*', label='Optimum')
optimizers_config = [
    {"name": "SGD", "kwargs": {"learning_rate": 0.01}, "label": "SGD"},
    {"name": "SGD", "kwargs": {"learning_rate": 0.001, "momentum": 0.9, "nesterov": True}, "label": "SGD-NAG"},
    {"name": "Adam", "kwargs": {"learning_rate": 0.1}, "label": "Adam"},
    {"name": "Adagrad", "kwargs": {"learning_rate": 0.1}, "label": "Adagrad"},
    {"name": "RMSprop", "kwargs": {"learning_rate": 0.05}, "label": "RMSprop"}
]
optimizers, states, plot_data = [], [], []
for optimizer in optimizers_config:
    optimizers.append(getattr(tf.keras.optimizers, optimizer['name'])(**optimizer['kwargs']))
    states.append((tf.Variable(x_init, name='x_{}'.format(optimizer['name'])), 
                   tf.Variable(y_init, name='y_{}'.format(optimizer['name']))))
    opt_plot, = plt.plot([x_init.numpy()], [y_init.numpy()], label=optimizer['label'])
    plot_data.append(opt_plot)
plt.title("Test optimization run with {} optimizers. Initial conditions x: {:.4f}, y: {:.4f}".format(
    len(optimizers), x_init.numpy(), y_init.numpy()), fontsize=14)

num_iterations = 100
for i in range(num_iterations):
    try:
        for optimizer, state, data in zip(optimizers, states, plot_data):
            grads = grad_fn(state[0], state[1])
            optimizer.apply_gradients(zip(grads, state))
            data.set_xdata(np.append(data.get_xdata(), state[0].numpy()))
            data.set_ydata(np.append(data.get_ydata(), state[1].numpy()))
        plt.text(0.01, 0.01, 'Iteration {}'.format(i+1), horizontalalignment='left', 
                 verticalalignment='bottom', transform = plt.gca().transAxes, 
                 fontsize=12, bbox=dict(facecolor='white', alpha=1.))
        plt.legend(fontsize=12)
        display.display(plt.gcf())
        display.clear_output(wait=True)
    except KeyboardInterrupt:
        break
6/11: import tensorflow as tf
 7/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
 8/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
 9/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
10/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
11/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
12/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
13/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
14/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
14/2: round(-5.5)
14/3: round(-5.5*2)/2
14/4: round(-5.5/2)*2
14/5: round(-3.5/2)*2
14/6: from tifffile import imread
14/7: a = imread('/home/miguel/Projects/uni/data/autofocus/cylindrical_lenses_openframe/20210525_40um_50nm_cylindrical_lenses/20210525_40um_50nm_MMStack_Default_1.ome.tif')
14/8: a.shape
14/9: a.nbytes
15/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
16/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
16/2: import numpy a snp
16/3: import numpy as np
16/4: np.random.poisson(10)
16/5: np.random.poisson(10)
16/6: np.random.poisson(10)
16/7: np.random.poisson(10)
16/8: np.random.poisson(10)
16/9: np.random.poisson(10)
16/10: np.random.poisson(10)
16/11: np.random.poisson(10)
16/12: np.random.poisson(10)
16/13: np.random.poisson(10)
16/14: np.random.poisson(10)
16/15: np.random.poisson(10)
16/16: np.random.poisson(10)
16/17: import matplotlib.pyplot as plt
16/18: plt.show()
17/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
17/2: float(2.5e-4)
18/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
18/2: import numpy as np
18/3: a = np.ndarray([[1, 2], [3,4]])
18/4: a = np.array([[1, 2], [3,4]])
18/5: a
18/6: a.shape
18/7: b = np.array([1,2])
18/8: b
18/9: a / b
18/10: a / a.max(axis=1)
18/11: a / a.max(axis=-1)
18/12: a / a.max(axis=-1)[:, np.newaxis]
19/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_segmentation', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/clustering_methods', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering', '/home/miguel/Projects/uni/phd/smlm_segmentation/graph-clustering/spectral_clustering/data', '/home/miguel/Projects/uni/phd/smlm_segmentation/caml/CAML', '/home/miguel/Projects/uni/phd/smlm_segmentation/old/PointCNN'])
19/2: [1,2] + [3,4]
19/3: import numpy as np
19/4: np.add([1,2], [3,4])
20/1:
print('PyDev console: using IPython 7.23.1\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/miguel/Projects/uni/phd/smlm_z', '/home/miguel/Projects/uni/phd/smlm_z/cnnSTORM/src'])
21/1:
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xgboost
from xgboost import XGBRegressor

from data.datasets import TrainingDataSet, ExperimentalDataSet
from util import get_base_data_path

DEBUG = False

USE_GPU = True
RESULTS_DIR = os.path.join(os.path.dirname(__file__), '..', 'src/wavelets/wavelet_data/output')

model_path = os.path.join(os.path.dirname(__file__), '/tmp/model.json')


def train_model(dataset, pretrained_model=None):
    for k, v in dataset.items():
        print(k, v[0].shape, v[1].shape)

    # # LightGBM

    #
    # param = {'num_leaves': 1000,
    #          'boosting_type': 'gbdt',
    #          'task': 'train',
    #          'objective': 'regression',
    #          'metric': 'mae',
    #          'device': 'gpu' if USE_GPU else 'cpu',
    #          'min_data_in_leaf': 50
    #          }
    #
    # model = lgb.LGBMRegressor(**param)
    #
    # num_round = 500
    #
    # model = model.fit(*dataset['train'], num_round, eval_set=[dataset['val']], early_stopping_rounds=3,
    #                   init_model=pretrained_model)
    #
    #

    # XGBoost
    model_options = {
        'n_estimators': 1000 if not DEBUG else 5,
        'gamma': 0,
        'max_bin': 1024,
        'max_depth': 8,
        'min_child_weight': 1,
        'verbosity': 1,
        'tree_method': 'gpu_hist',
        'n_jobs': 4,
        'nthread': 4
    }

    for i in range(2):
        try:
            if pretrained_model is None:
                model = XGBRegressor(**model_options, learning_rate=0.1)
            else:
                model = pretrained_model

            if os.path.exists(model_path):
                if 'y' in input('Load saved model?'):
                    model.load_model(model_path)
                    return model
            model.fit(*dataset['train'],
                      eval_metric='mae',
                      eval_set=[dataset['val']],
                      early_stopping_rounds=3,
                      verbose=True,
                      )
            model.save_model(model_path)

        except xgboost.core.XGBoostError:
            del model_options['tree_method']
            # del model_options['num_parallel_tree']
            continue
        break

    # NN model
    # from tensorflow.keras.layers import Dense
    # from tensorflow.keras import Sequential, optimizers
    # from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    # from tensorflow.python.keras.layers import BatchNormalization
    # import matplotlib.pyplot as plt
    # if pretrained_model:
    #     model = pretrained_model
    # else:
    #     model = Sequential([
    #         Dense(2000, activation='relu'),
    #         Dense(2000, activation='relu'),
    #         Dense(2000, activation='relu'),
    #         Dense(1, activation='linear')
    #     ])
    #
    #     optimizer = optimizers.Adam(learning_rate=0.0001)
    #     model.compile(loss='mse', optimizer=optimizer, metrics=['MeanAbsoluteError'])
    # #
    # callbacks = [
    #     EarlyStopping(monitor='val_mean_absolute_error', patience=10, verbose=True),
    #     ReduceLROnPlateau(monitor='val_mean_absolute_error', patience=3, verbose=True)
    # ]
    #
    # history = model.fit(*dataset['train'], batch_size=512, epochs=1000, validation_data=(*dataset['val'],),
    #                     callbacks=callbacks)
    # plt.plot(history.history['mean_absolute_error'], label='train')
    # plt.plot(history.history['val_mean_absolute_error'], label='val')
    # plt.legend()
    # plt.show()

    return model
    # num_round = 500
    # model = model.fit(*train_dataset, num_round, eval_set=[val_dataset], early_stopping_rounds=5, verbose=True)


def eval(model, test_dataset, title):
    x, y = test_dataset
    y_pred = model.predict(x)
    ae = abs(y_pred - y.squeeze())
    plt.boxplot(ae)
    plt.title(f'{title} MAE: {round(ae.mean(), 4)} STDev: {round(ae.std(), 4)}')
    plt.ylabel('Absolute error (nm)')
    plt.show()
    print('MAE:', round(ae.mean(), 4))
    return ae.mean(), ae.std()


def predict(model, exp_dataset, fname):
    z = model.predict(exp_dataset['wavelets'])
    df = exp_dataset['df']
    df['z [nm]'] = z

    outpath = os.path.join(RESULTS_DIR, fname)
    df.to_csv(outpath)
    return df


def visualise_dataset(fname):
    outpath = os.path.join(RESULTS_DIR, fname)

    df = pd.read_csv(outpath)
    print(df.shape)
    n_samples = 5000000
    if df.shape[0] > n_samples:
        df = df.sample(n_samples)
    fig = plt.figure()
    plt.set_cmap('brg')

    ax = fig.add_subplot(projection='3d')

    x = df['x [nm]']
    y = df['y [nm]']
    z = df['z [nm]']
    ax.set_box_aspect((np.ptp(x), np.ptp(y), np.ptp(z) * 100))

    ax.scatter(x, y, z, marker='.', s=3, c=z)
    plt.show()


def main():
    # # # Get jonny bead stacks
    # jonny_dataset = load_jonny_dataset(50000, 1000)
    # # Train model
    # model = train_model(jonny_dataset)

    #
    # print('Multiwell trained')
    # eval(model, test_bead_stack['test'])
    #
    # model = train_model(test_bead_stack, model)
    # print('Retrained')
    # eval(model, test_bead_stack['test'])

    # TODO LUPUS NEPHRITIS - Subsampling test
    # Red stack
    # dwt_level = [9]
    # results = []
    # for d in dwt_level:
    #     test_bead_stack = load_red_lupus_nephritis_bead_stack(level=d)
    #     model = train_model(test_bead_stack, None)
    #     mae, std = eval(model, test_bead_stack['test'], 'Lupus Nephritis red channel')
    #     results.append({
    #         'dwt_level': d,
    #         'error': mae,
    #         'std': std
    #     })
    #     del model
    #     gc.collect()
    # df = pd.DataFrame.from_records(results)
    # df.plot(x='dwt_level', y='error', yerr='std', capsize=4)
    # plt.ylabel('Axial localisation error (nm)')
    # plt.xlabel('Wavelet decomposition level')
    # plt.show()
    # print(df)

    # LUPUS NEPHRITIS
    # Red stack
    # red_bead_stack = load_red_lupus_nephritis_bead_stack()
    # model = train_model(red_bead_stack, None)
    # eval(model, red_bead_stack['test'], 'Lupus Nephritis red channel')
    # red_exp_data = load_red_lupus_nephritis_experimental_data()
    # predict(model, red_exp_data, 'lupus_red.csv')

    # Green stack
    # green_bead_stack = load_green_lupus_nephritis_bead_stack()
    # model = train_model(green_bead_stack, None)
    # eval(model, green_bead_stack['test'], 'Lupus Nephritis green channel')
    # green_exp_data = load_green_lupus_nephritis_experimental_data()
    # predict(model, green_exp_data, 'lupus_green.csv')

    # membranous_glomerulonephritis
    # Red stack
    # red_bead_stack = load_red_membranous_glomerulonephritis_bead_stack()
    # model = train_model(red_bead_stack, None)
    # eval(model, red_bead_stack['test'], 'Membranous glomerulonephritis red channel')
    # red_exp_data = load_red_membranous_glomerulonephritis_experimental_data()
    # predict(model, red_exp_data, 'membranous_glomerulonephritis_red.csv')
    # visualise_dataset('membranous_glomerulonephritis_red.csv')

    # Green stack
    # green_bead_stack = load_green_membranous_glomerulonephritis_bead_stack()
    # model = train_model(green_bead_stack, None)
    # eval(model, green_bead_stack['test'], 'Membranous glomerulonephritis green channel')
    # green_exp_data = load_green_membranous_glomerulonephritis_experimental_data()
    # predict(model, green_exp_data, 'membranous_glomerulonephritis_green.csv')
    # visualise_dataset('membranous_glomerulonephritis_green.csv')
    #
    # bead_stack = load_olympus_3d_bead_stack()
    # model = train_model(bead_stack, None)
    # eval(model, bead_stack['test'], 'Olympus 3d')

    # 11nm bead stack
    # mm11_bead_stack = load_11mm_bead_stack()
    # model = train_model(mm11_bead_stack, None)
    # eval(model, mm11_bead_stack['test'], 'MM11 bead stack')
    # dfs = []
    # for slc in range(10, 160, 10):
    #     print(f'Slice {slc}')
    #     try:
    #         mm11_exp_data = load_11mm_experimental_data(slc)
    #         df = predict(model, mm11_exp_data, 'mm11_bead_stack.csv')
    #         dfs.append(df)
    #     except IndexError:
    #         break
    # df = pd.concat(dfs, ignore_index=True)
    # df.to_csv('mm11_bead_stack.csv')
    # visualise_dataset('mm11_bead_stack.csv')

    # Retrained MAE: 122nm
    """
    LGB
        60nm
        123 retrained
        78 from scratc
    
    XGBoost
        62nm
        73nm retrained
        73nm from scratch
        
    NN
        63nm
        411 retrained
        77.9 from scratch
    """

    # Train on bead stack
    # Eval model on exp bead stack

    # Run on exp data
    z_range = 1000

    train_dpath = get_base_data_path() / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (0, 65, 65)
    z_step = 2000

    train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)

    exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    model = train_model(train_dataset.data)
    eval(model, train_dataset.data['test'], 'Bead stack')

    result_coords = exp_dataset.predict_dataset(model)

    df = pd.DataFrame(data=result_coords, columns=['x', 'y', 'z'])

    res_file = os.path.join(os.path.dirname(__file__), 'tmp', 'res.csv')
    df.to_csv(res_file, index=False)


if __name__ == '__main__':
    main()
22/1:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters()
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
23/1:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters()
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
24/1:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters()
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
24/2:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters()
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
24/3:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters()
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
25/1:
import math
import os

from scipy.spatial.distance import cdist
from tifffile import imread, imshow
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

from data.estimate_offset import estimate_offset
from data.visualise import scatter_3d
from util import get_base_data_path, split_for_training, dwt_dataset

dwt_level = 8

DEBUG = False


class GenericDataSet:
    filter_emitters_proximity = True
    filter_emitters_edges = True
    filter_low_intensity_emitters = True
    voxel_sizes = None
    bound = 20

    def __init__(self, dpath, imname, csv_path, voxel_sizes):
        self.impath = os.path.join(dpath, imname)
        self.img = imread(self.impath)
        csv_path = os.path.join(dpath, csv_path)

        print(f'Loading {self.impath}')
        print(f'Loading {csv_path}')

        self.csv_data = pd.read_csv(csv_path)
        self.voxel_sizes = voxel_sizes

    @staticmethod
    def transform_input(psfs):
        psfs = psfs / psfs.max(axis=(1, 2))[:, np.newaxis, np.newaxis]

        return dwt_dataset(psfs, level=dwt_level)

    def remap_emitter_coords(self, image, df):
        # Change origin from centre of image to top left corner
        # x_center = (image.shape[-1] * self.voxel_sizes[-1] / 2)
        # y_center = (image.shape[-2] * self.voxel_sizes[-2] / 2)
        # df['x [nm]'] += x_center
        # df['y [nm]'] = (-df['y [nm]']) + y_center
        return df

    @staticmethod
    def localisation2pixel(df, voxel_size):
        x_pixel = (df['x [nm]'] / voxel_size[-1])
        y_pixel = (df['y [nm]'] / voxel_size[-2])
        return x_pixel, y_pixel

    @staticmethod
    def cut_image_stack(image, center, width=16, show=False):
        """

        :param image: numpy array representing image
        :param center: emitter position from truth or STORM
        :param width: window around emitter
        :param show: io.imshow returns cut-out of PSF
        :return: cut out of PSF as a numpy array
        """

        # NOTE: for some reason numpy images seem to have x and y swapped in the logical
        # order as would be for a coordinate point (x,y). I.e. point x,y in the image
        # is actually image[y,x]

        x_min, x_max = int(center[1] - width), int(center[1] + width)
        y_min, y_max = int(center[0] - width), int(center[0] + width)
        if image.ndim == 3:
            cut = image[:, x_min:x_max, y_min:y_max]
        else:
            cut = image[x_min:x_max, y_min:y_max]

        if show:
            imshow(cut)
            plt.show()
        return cut

    @staticmethod
    def filter_localisations(df, im_size, bound, voxel_sizes, edges=True, proximity=True):
        x_col = 'x [nm]'
        y_col = 'y [nm]'

        def check_borders(emitter):
            x_nm, y_nm = emitter[x_col], emitter[y_col]
            x_pixel = x_nm / voxel_sizes[-1]
            y_pixel = y_nm / voxel_sizes[-2]

            x_valid = (0 + bound <= x_pixel <= im_size[-1] - bound)
            y_valid = (0 + bound <= y_pixel <= im_size[-2] - bound)

            return x_valid and y_valid

        print(f'{df.shape[0]} emitters before filtering')

        if edges:
            df = df[df.apply(check_borders, axis=1)]
            print(f'{df.shape[0]} emitters after borders')

        if proximity:
            min_seperation = math.sqrt(2) * bound * voxel_sizes[-1]

            num_emitters = df.shape[0]
            filters = []
            for i in range(0, num_emitters - 1):
                emitter = df.iloc[i, :]
                emitter_coords = emitter[[x_col, y_col]].to_numpy()[np.newaxis]

                other_emitters = df.iloc[i + 1:, :]
                other_coords = other_emitters[[x_col, y_col]].to_numpy()

                min_dist = cdist(emitter_coords, other_coords).min()
                filters.append(min_dist >= min_seperation)

            # Last value is always kept
            filters.append(True)
            df = df.loc[filters]
            print(f'{df.shape[0]} emitters after proximity filtering.')
        return df


    def fetch_emitters(self, img, df, base_z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        self.csv_data = filtered_df
        psfs = []
        xyz_coords = []

        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            try:
                z_pos = estimate_offset(psf, self.voxel_sizes)

                valid_ids = np.where(abs(z_pos) < self.z_range)
                psf = psf[valid_ids]
                z_pos = z_pos[valid_ids]

                xy_coord = np.tile(filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy(), reps=(len(z_pos), 1))
                xyz_coord = np.hstack((z_pos[:, np.newaxis], xy_coord))

                psfs.append(psf)
                xyz_coords.append(xyz_coord)
                if DEBUG:
                    break
            except RuntimeError as e:
                print(e)

        xyz_coords = np.concatenate(xyz_coords)
        return psfs, xyz_coords

    def fetch_emitters_coords(self, img, df):
        if 'Fit valid' in df:
            df = df[df['Fit valid'] == 1]

        if self.filter_low_intensity_emitters and 'intensity [photon]' in df:
            df = df[df['intensity [photon]'] > 2500]

        if 'x0 (um)' in df:
            df = df[["x0 (um)", "y0 (um)", "z0 (um)"]]
            # Convert to nm for thresholding
            for a, b in (("x0 (um)", "x [nm]"), ("y0 (um)", "y [nm]"), ("z0 (um)", "z [nm]")):
                df.loc[:, b] = df.loc[:, a] * 1000
                del df[a]

        df = self.remap_emitter_coords(img, df)

        df = self.filter_localisations(df, img.shape, self.bound, self.voxel_sizes,
                                       edges=self.filter_emitters_edges, proximity=self.filter_emitters_proximity)

        pixel_x, pixel_y = self.localisation2pixel(df, voxel_size=self.voxel_sizes)
        pixel_x = np.round(pixel_x).astype(int)
        pixel_y = np.round(pixel_y).astype(int)
        emitter_coords = list(zip(pixel_x, pixel_y))
        return emitter_coords, df


class TrainingDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, voxel_sizes, z_range, filter_emitters_proximity=True, filter_low_intensity_emitters=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        self.filter_emitters_proximity = filter_emitters_proximity
        self.filter_low_intensity_emitters = filter_low_intensity_emitters

        self.z_range = z_range
        psfs, xyz_pos = self.fetch_emitters(self.img, self.csv_data)

        self.all_coords = xyz_pos

        # Split images into distinct train/val/test
        psfs = np.concatenate(psfs)
        input_data = self.transform_input(psfs)
        input_data = np.hstack((input_data, xyz_pos[:, (1,2)]))
        target_data = xyz_pos[:, 0]
        self.data = split_for_training(input_data, target_data)


        # Split emitter stacks into distinct train/val/test
        # self.data = split_for_training(psfs, xyz_pos)
        # for k in self.data:
        #     self.data[k][0] = np.concatenate(self.data[k][0])
        #     self.data[k][0] = self.transform_input(self.data[k][0])
        #     self.data[k][1] = np.concatenate(self.data[k][1])
        #
        #     # Add XY coordinates into input data
        #     self.data[k][0] = np.hstack((self.data[k][0], self.data[k][1][:, (1, 2)]))
        #     self.data[k][1] = self.data[k][1][:, 0]


class ExperimentalDataSet(GenericDataSet):
    def __init__(self, dpath, imname, csv_path, z_step=None, voxel_sizes=None, filter_localisations=True):
        super().__init__(dpath, imname, csv_path, voxel_sizes)
        if not filter_localisations:
            self.filter_emitters_proximity = False
            self.filter_low_intensity_emitters = False
    
        if len(self.img.shape) == 3:
            if z_step is None:
                raise AssertionError('Z-step not specified but data is 3D')
            self.z_step = z_step

        psfs, coords = self.fetch_all_emitters()

        input_data = self.transform_input(psfs)

        input_data = np.hstack((input_data, coords[:, (1, 2)]))
        self.data = (input_data, coords)

    def estimate_ground_truth(self):
        return super(ExperimentalDataSet, self).fetch_emitters(self.img, self.csv_data)
        


    def fetch_emitters(self, img, df, z_coord=0):
        pixel_coords, filtered_df = self.fetch_emitters_coords(img, df)
        xyz_coords = []

        psfs = np.zeros((len(pixel_coords), self.bound * 2, self.bound * 2))
        for i, pixel_coord in enumerate(tqdm(pixel_coords)):
            psf = self.cut_image_stack(img, pixel_coord, width=self.bound)
            psfs[i] = psf
            xy_coord = filtered_df.iloc[i][['x [nm]', 'y [nm]']].to_numpy()
            xyz_coords.append(list(xy_coord) + [z_coord])
        return psfs, xyz_coords

    def fetch_all_emitters(self):
        all_psfs = []
        all_coords = []
        for slice_id in range(self.img.shape[0]):
            img = self.img[slice_id]
            df = self.csv_data[self.csv_data['frame'] == (slice_id + 1)]

            psfs, coords = self.fetch_emitters(img, df, slice_id * self.z_step)
            all_psfs.append(psfs)
            all_coords.extend(coords)

        all_coords = np.array(all_coords)
        all_psfs = np.concatenate(all_psfs)
        return all_psfs, all_coords

    def predict_dataset(self, model):
        input_data, coords = self.data
        coord_diff = model.predict(input_data)

        coords[:, 2] = coords[:, 2] + coord_diff
        scatter_3d(coords)
        return coords


z_range = 2000

if __name__ == '__main__':
    # Olympus data
    train_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / 'glass_beads_pbs_1'
    train_img = 'glass_beads_pbs_1_MMStack_Default.ome.tif'
    train_csv = 'glass_beads_pbs_1_MMStack_Default.csv'
    train_voxel_sizes = (50, 65, 65)

    exp_dpath = get_base_data_path() / '..' / 'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    exp_img = '1mm_beads_agarose_centre_1_MMStack_Default_substack.tif'
    exp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    exp_voxel_sizes = (2500, 65, 65)
    z_step = 2500

    # train_dataset = TrainingDataSet(train_dpath, train_img, train_csv, train_voxel_sizes, z_range)
    # exp_dataset = ExperimentalDataSet(exp_dpath, exp_img, exp_csv, voxel_sizes=exp_voxel_sizes, z_step=z_step)

    tmp_dpath = get_base_data_path() /  'bead_3D_STORM_three_instruments' / '20210723_Olympus_beads' / '1mm_beads_agarose_centre_1'
    tmp_img = '1mm_beads_agarose_centre_1_MMStack_Default.ome.tif'
    tmp_csv = '1mm_beads_agarose_centre_1_MMStack_Default_substack.csv'
    tmp_voxel_sizes = (50, 65, 65)
    tmp_dataset = ExperimentalDataSet(tmp_dpath, tmp_img, tmp_csv, voxel_sizes=tmp_voxel_sizes, z_step=z_step, filter_localisations=False)
    tmp_dataset.estimate_ground_truth()
    print('s')
26/1:
from functools import partial
import glob
import numpy as np
import os
from numpy.random import shuffle
from tifffile import imread
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import pywt

from src.autofocus.estimate_offset import estimate_offset, resize_img
from src.autofocus.config import cfgs, get_cfg_images, dwt_level

def dwt_transform(img, wavelet='sym4', level=3):
    img = img / img.max()
    coeffs2 = pywt.wavedecn(img, wavelet, level=level)
    coeffs = pywt.coeffs_to_array(coeffs2)[0].flatten()
    return coeffs

def dwt_dataset(psfs, wavelet='sym4', level=3):
    print(f'Running Wavelet transform for dataset at level: {level}')
    func = partial(dwt_transform, wavelet=wavelet, level=level)
    # with Pool(8) as p:
    x = list(map(func, psfs.squeeze()))
    x = np.stack(x)

    return x


def remove_low_variance_features(xs):
    # Remove features with low variance to reduce memory footprint
    xs_vars = np.var(xs, axis=0)
    cols = np.where(xs_vars > 0.1)[0]
    print(f'Removing {xs.shape[1] - len(cols)} features with low variance.')
    xs = xs[:, cols]

    print(f'X: {round(xs.nbytes / (10 ** 9), 3)} GB')
    return xs, cols    

def split_dataset(xs, ys):
    x_train, x_other, y_train, y_other = train_test_split(xs, ys, train_size=0.8)
    x_val, x_test, y_val, y_test = train_test_split(x_other, y_other, train_size=0.5)

    return {
        'train': (x_train, y_train),
        'val': (x_val, y_val),
        'test': (x_test, y_test)
    }


def transform_img(impath, dwt_level):
    outpath = get_dwt_transform_path(impath, dwt_level)
    if not os.path.exists(outpath):
        print(impath)
        img = imread(impath)
        img = resize_img(img)
        dwt = dwt_dataset(img, level=dwt_level, wavelet='sym4')
        print(np.argwhere(np.isnan(dwt)).shape)
        dwt = dwt.astype(np.float16)
        print(np.argwhere(np.isnan(dwt)).shape)
        quit()
        np.savez(outpath, dwt)
        del img
        del dwt


def transform_data(imgs, dwt_level):
    for img in tqdm(imgs):
        transform_img(img, dwt_level)
    # process_map(transform_img, imgs, max_workers=4)


def get_dwt_transform_path(impath, dwt_level):
    return impath.replace('.tif', f'_{dwt_level}.npz')


def get_axial_position_file(impath):
    return impath.replace('.tif', '.offset.npz')


def prepare_axial_positions(imgs, voxel_sizes, row_avg):
    for impath in tqdm(imgs):
        outpath = get_axial_position_file(impath)

        if not os.path.exists(outpath):
            print(impath)
            img = imread(impath)

            y = estimate_offset(img, voxel_sizes=voxel_sizes, row_avg=row_avg)
            np.savez(outpath, y)
            del img


def gather_data(imgs, slc, dwt_level):
    xs = []
    ys = []

    for impath in tqdm(imgs[slc]):
        dwt_path = get_dwt_transform_path(impath, dwt_level)
        xs.append(np.load(dwt_path)['arr_0'])

        axial_position_path = get_axial_position_file(impath)
        ys.append(np.load(axial_position_path)['arr_0'])
    xs = np.concatenate(xs)
    ys = np.concatenate(ys)

    xs = xs.astype(np.float32)
    ys = ys.astype(np.float32)
    
    return xs, ys


if __name__ == '__main__':
    for cfg in cfgs.values():
        print(f'Processing {cfg}')
        vs = cfg['z_voxel']
        images = get_cfg_images(cfg)
        
        print(f'Found {len(images)} images.')

        all_vs = (vs, None, None)
        transform_data(images, dwt_level)
        prepare_axial_positions(images, all_vs, cfg['row_avg'])
26/2:
import pywt
from tifffile import imread
d = imread('/home/miguel/Projects/uni/data/autofocus/cylindrical_lenses_openframe/20210525_40um_50nm_cylindrical_lenses/20210525_40um_50nm_MMStack_Default.ome.tif')
26/3: d
26/4: pywt.wavedecn(d, 'sym4', level=4)
27/1: rows = []
28/1: print(reg.coef_)
35/1:
import pandas as pd
import numpy as np
35/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
35/3:
print(list(coords))
print(imgs.shape)
35/4:
print(list(coords_error))
print(imgs.shape)
35/5: coords_error.histogram('error')
35/6: coords_error.hist('error')
35/7: coords_error['failure'] = coords_error['error'] > 30
35/8: print(sum(coords_error['failure'])/len(coords_error['failure']))
35/9: coords_error['failure'] = coords_error['error'] > 50
35/10: print(sum(coords_error['failure'])/len(coords_error['failure']))
35/11: print(coords_error['error'].mean())
36/1:
import pandas as pd
import numpy as np
36/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
36/3:
print(list(coords_error))
print(imgs.shape)
36/4: coords_error.hist('error')
36/5: coords_error['failure'] = coords_error['error'] > 50
36/6: print(sum(coords_error['failure'])/len(coords_error['failure']))
36/7: print(coords_error['error'].mean())
36/8:
import pandas as pd
import numpy as np
36/9:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
36/10:
print(list(coords_error))
print(imgs.shape)
36/11: coords_error.hist('error')
36/12: coords_error['failure'] = coords_error['error'] > 50
36/13: print(sum(coords_error['failure'])/len(coords_error['failure']))
36/14: print(coords_error['error'].mean())
36/15:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where((not coords_error['failure']))[0]
print(good_images_idx)
36/16:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where((coords_error['failure'].not()))[0]
print(good_images_idx)
36/17:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(coords_error['failure'].not())[0]
print(good_images_idx)
36/18:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
print(good_images_idx)
36/19:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
36/20: coords_error['failure'] = coords_error['error'] > 70
36/21:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
36/22: from experiments.signal_noise_ratio import estimate_nsr_ratio
36/23: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
36/24: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
36/25: coords_error['nsr'].groupby('failure').boxplot('nsr')
36/26: coords_error.groupby('failure').boxplot('nsr')
36/27:
set(coords_error['failure'])
coords_error.groupby('failure').boxplot('nsr')
36/28:
print(set(coords_error['failure']))
coords_error.groupby('failure').boxplot('nsr')
36/29: coords_error.groupby('failure')
36/30: print(coords_error.groupby('failure'))
36/31: coords_error.groupby('failure').boxplot('nsr')
36/32: coords_error.boxplot('nsr')
36/33: coords_error.groupby('failure').boxplot('nsr')
36/34:
plt.xtickets(rot=45)
coords_error.groupby('failure').boxplot('nsr')
36/35:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
36/36:

plt.xtickets(rot=45)
coords_error.groupby('failure').boxplot('nsr')
36/37:

plt.xtick(rot=45)
coords_error.groupby('failure').boxplot('nsr')
36/38:

plt.xticks(rot=45)
coords_error.groupby('failure').boxplot('nsr')
36/39:

plt.xticks(rotation=45)
coords_error.groupby('failure').boxplot('nsr')
36/40:

plt.xticks(rotation=90)
coords_error.groupby('failure').boxplot('nsr')
36/41:

coords_error.groupby('failure').boxplot('nsr')
plt.xticks(rotation=90)
36/42:

coords_error.groupby('failure')['nsr'].boxplot('nsr')
plt.xticks(rotation=90)
36/43:

coords_error.groupby('failure').boxplot('nsr')
plt.xticks(rotation=90)
36/44:

coords_error.groupby('failure')[['nsr']].boxplot('nsr')
plt.xticks(rotation=90)
36/45:

coords_error.groupby('failure').boxplot(column='nsr')
plt.xticks(rotation=90)
36/46:

coords_error.groupby('failure').boxplot()
plt.xticks(rotation=90)
36/47:

coords_error.groupby('failure').boxplot('nsr')
plt.xticks(rotation=90)
36/48:
coords_error.groupby('failure').boxplot(column='nsr')
plt.xticks(rotation=90)
36/49:
coords_error.boxplot(column='nsr')
plt.xticks(rotation=90)
36/50:
coords_error[['failure', 'nsr']].boxplot(column='nsr')
plt.xticks(rotation=90)
36/51:
coords_error[['failure', 'nsr']].groupby('nsr').boxplot(column='nsr')
plt.xticks(rotation=90)
37/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
37/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
37/3:
print(list(coords_error))
print(imgs.shape)
37/4: coords_error.hist('error')
37/5: coords_error['failure'] = coords_error['error'] > 70
37/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
37/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
37/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
37/9: coords_error[['failure', 'nsr']].groupby('nsr')
37/10: coords_error[['failure', 'nsr']].groupby('nsr').boxplot(column='nsr')
37/11: coords_error.groupby('nsr').boxplot(by='nsr')
37/12: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
37/13: coords_error.groupby('nsr').boxplot(by='nsr')
37/14: coords_error.boxplot('nsr')
37/15: coords_error.boxplot('nsr', by='failure')
37/16: coords_error.histogram('nsr', by='failure')
37/17: coords_error.hist('nsr', by='failure')
37/18: coords_error.histogram('nsr', by='failure')
37/19: coords_error.boxplot('nsr', by='failure')
37/20:
all_images = np.concatenate((good_images, bad_images))
labels = np.stack(np.ones((good_images.shape[0],)), np.zeros((bad_images.shape[0],)))
37/21:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate(np.ones((good_images.shape[0],)), np.zeros((bad_images.shape[0],)))
37/22:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate(np.ones((good_images.shape[0], 1)), np.zeros((bad_images.shape[0], 1)))
37/23:
all_images = np.concatenate((good_images, bad_images))
np.ones((55,1))
labels = np.concatenate(np.ones((good_images.shape[0], 1)), np.zeros((bad_images.shape[0], 1)))
37/24:
all_images = np.concatenate((good_images, bad_images))
good_images.shape[0]
labels = np.concatenate(np.ones((good_images.shape[0], 1)), np.zeros((bad_images.shape[0], 1)))
37/25:
all_images = np.concatenate((good_images, bad_images))
print(good_images.shape[0])
labels = np.concatenate(np.ones((good_images.shape[0], 1)), np.zeros((bad_images.shape[0], 1)))
37/26:
all_images = np.concatenate((good_images, bad_images))
print(good_images.shape[0])
labels = np.ones((good_images.shape[0])
37/27:
all_images = np.concatenate((good_images, bad_images))
print(good_images.shape[0])
labels = np.ones((good_images.shape[0]))
37/28:
all_images = np.concatenate((good_images, bad_images))

labels = np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))
37/29:
all_images = np.concatenate((good_images, bad_images))

labels = np.stack(np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))
print(labels.shape)
37/30:
all_images = np.concatenate((good_images, bad_images))

labels = np.stack((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
print(labels.shape)
37/31:
all_images = np.concatenate((good_images, bad_images))

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
print(labels.shape)
37/32:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
37/33: from experiments.dataset_classifier import load_discriminator
37/34:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratified=True)
37/35:
from experiments.dataset_classifier import load_discriminator
import tensorflow as tf
37/36:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratified=True)
37/37:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratified=True)
37/38:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratify=True)
37/39:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratify=True)
37/40:
from experiments.dataset_classifier import load_discriminator
import tensorflow as tf
37/41:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratify=True)
37/42:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, stratify=labels) 
print()
37/43:
from sklearn.model_selection import train_test_split
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels)
37/44:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
37/45:
callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True),
    TensorBoard(log_dir=log_dir, histogram_freq=1)
]
model.fit((train_x, train_y), validation_data)
37/46:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True),
    TensorBoard(log_dir=log_dir, histogram_freq=1)
]
model.fit((train_x, train_y), validation_data)
37/47:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit((train_x, train_y), validation_data)
37/48:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit((train_x, train_y), validation_data=((val_x, val_y),), epochs=100)
37/49:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
print(train_x.shape)
model.fit(train_x, train_y, validation_data=((val_x, val_y),), epochs=100)
37/50:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, validation_data=((val_x, val_y),), epochs=100)
37/51:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=((val_x, val_y),))
37/52:
from experiments.dataset_classifier import load_discriminator
import tensorflow as tf
37/53:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
37/54:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=((val_x, val_y),))
37/55:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/56:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100)
37/57:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=((val_x, val_y),))
37/58:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/59:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=[val_x, val_y])
37/60:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
37/61:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=[val_x, val_y])
37/62:
print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)
37/63:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=(*[val_x, val_y])
37/64:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=(*[val_x, val_y]))
37/65:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=([val_x, val_y]))
37/66:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=[val_x, val_y])
37/67:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=[(val_x, val_y)])
37/68:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=[(val_x, val_y),])
37/69:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y),)
37/70:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]
print(val_x.shape)
print(val_y.shape)
model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y),)
37/71:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y),)
37/72:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/73:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/74:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/75:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = val_x, val_y
model.fit(*train_data, epochs=100, validation_data=(*val_data))
37/76:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = val_x, val_y
model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/77:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = val_x, val_y
print(model.summary())
model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/78:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

val_data = train_x, train_y
train_data = val_x, val_y
print(model.summary())
model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/79:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

val_data = train_x, train_y
train_data = val_x, val_y
model.fit(*train_data, epochs=100)
37/80:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

val_data = train_x, train_y
train_data = val_x, val_y
model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/81:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

val_data = train_x, train_y
train_data = val_x, val_y
print(val_x.shape)
print(val_y.shape)
model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/82:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

val_data = train_x, train_y[:, np.newaxis]
train_data = val_x, val_y[:, np.newaxis]

model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/83:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y[:, np.newaxis]
val_data = val_x, val_y[:, np.newaxis]

model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/84:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y[:, np.newaxis]
val_data = val_x, val_y[:, np.newaxis]

model.fit(*train_data, epochs=100, validation_data=val_data)
37/85:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = val_x, val_y

model.fit(*train_data, epochs=100, validation_data=val_data)
37/86:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(*train_data, epochs=100, validation_data=(val_data,))
37/87:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(*train_data, epochs=100, validation_data=(*val_data,))
37/88:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(*train_data, epochs=100, validation_data=(*train_data,))
37/89:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(*train_data, epochs=100, validation_data=[(val_x, val_y)])
37/90:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(*train_data, epochs=100, validation_data=(val_x, val_y))
37/91:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/92:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

train_data = train_x, train_y
val_data = [val_x, val_y]

model.fit(train_x, train_y, epochs=100, validation_data=(train_x, train_y))
37/93:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

print(type(train_x), type(val_x))

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/94:
import torchvision
import torch.nn as nn

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model
37/95:
import torchvision
import torch.nn as nn

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
37/96:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/97:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
37/98:
print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)
37/99:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))
37/100:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=1000, validation_data=(val_x, val_y))
37/101:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=1000, validation_data=(val_x, val_y), verbose=True, callbacks=callbacks)
37/102: import shap
37/103:
import shap

background = val_x[:100]
test_images = val_x[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/104:
import shap

background = val_x[:100]
test_images = val_x[100:103]
print(shap.framework)
e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/105:
import shap

background = val_x[:100]
test_images = val_x[100:103]
print(shap.__dict__)
e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/106:
import shap

background = val_x[:100]
test_images = val_x[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/107:
import shap
print(model.summary())
return
background = val_x[:100]
test_images = val_x[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/108:
import shap
print(model.summary())

background = val_x[:100]
test_images = val_x[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/109:
import shap

background = val_x[:100]
test_images = val_x[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/110:
import shap

background = val_x[:100]
test_images = val_x[100:103]
37/111:
e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
37/112:
from torch import nn
import torchvision

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model
37/113:
from torch import nn
import torchvision
import torch.optim as optim

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)

callbacks = []
37/114:
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)

callbacks = []
37/115:
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


callbacks = []
37/116:
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef

SEED = 42

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='ddp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/117:
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef

SEED = 42

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='ddp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/118:
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='ddp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/119:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='ddp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/120:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='ddp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/121:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/122:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/123:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)
37/124:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
38/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
38/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
38/3:
print(list(coords_error))
print(imgs.shape)
38/4: coords_error.hist('error')
38/5: coords_error['failure'] = coords_error['error'] > 70
38/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
38/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
38/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
38/9: coords_error.boxplot('nsr', by='failure')
38/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
38/11:
from experiments.dataset_classifier import load_discriminator
import tensorflow as tf
38/12:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
38/13:
print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)
38/14:
from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

callbacks = [
    ReduceLROnPlateau(
    monitor='loss', factor=0.1, patience=3, verbose=True,
    mode='min', min_delta=0.01, cooldown=0, min_lr=0,),
    EarlyStopping(monitor='accuracy', patience=5, verbose=True, min_delta=0.01, restore_best_weights=True)
]

model.fit(train_x, train_y, epochs=1000, validation_data=(val_x, val_y), verbose=True, callbacks=callbacks)
38/15:
# import torch
# from torch import nn
# import torchvision
# import torch.optim as optim
# from sklearn.model_selection import train_test_split

# from pytorch_lightning import LightningModule, Trainer, seed_everything
# from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
# from pytorch_lightning.loggers import TensorBoardLogger
# from torch.optim.lr_scheduler import MultiStepLR
# from torch.optim.swa_utils import AveragedModel, update_bn
# from torchmetrics.functional import accuracy, confusion_matrix
# from sklearn.model_selection import StratifiedShuffleSplit
# from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
# from torch.utils.data import Dataset

# SEED = 42
# BATCH_SIZE=1000

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class FullDataset(Dataset):
#     """Basic class encapulating dataset functions, for use with dataloader."""

#     def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
#         """Initialise with numpy array."""
#         self.img_data = img_numpy_array
#         self.labels = torch.from_numpy(labels_numpy_array)
#         print("Array shape loaded into torch dataset:", self.img_data.shape)

#     def __len__(self) -> int:
#         """Return length of dataset."""
#         assert self.img_data.shape[0] == self.labels.shape[0]
#         return self.img_data.shape[0]

#     def __getitem__(self, idx) -> torch.Tensor:
#         """Return items from dataset as torch tensors."""
#         img_data_selection = self.img_data[idx]
#         img_tensor = torch.from_numpy(img_data_selection).float()
#         return (img_tensor, self.labels[idx])


# class LitResnet(LightningModule):
#     def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
#         super().__init__()

#         self.save_hyperparameters()
#         self.model = create_model(num_classes)
        
#         self.train_dataset_len = train_dataset_len

#     def forward(self, x):
#         out = self.model(x)
#         return F.log_softmax(out, dim=1)

#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         loss = F.nll_loss(logits, y)
#         self.log("train_loss", loss, prog_bar=True)
#         return loss

#     def evaluate(self, batch, stage=None):
#         x, y = batch
#         logits = self(x)
#         loss = F.nll_loss(logits, y)
#         preds = torch.argmax(logits, dim=1)
#         micro_acc = accuracy(preds, y, average="micro")
#         macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

#         return {
#             "loss": loss.cpu(), 
#             "micro_acc": micro_acc.cpu(),
#             "macro_acc": macro_acc.cpu(),
#             "preds": preds.cpu(),
#             "labels": y.cpu()
#         }
    
#     def evaluation_epoch_end(self, outputs, stage=None):
#         micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
#         macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
#         loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
#         self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
#         # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
#         # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
#         # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

#     def validation_step(self, batch, batch_idx):
#         metrics = self.evaluate(batch, "val")
#         return metrics
    
#     def validation_epoch_end(self, outputs):
#         self.evaluation_epoch_end(outputs, "val")

#     def test_step(self, batch, batch_idx):
#         metrics = self.evaluate(batch, "test")
#         return metrics
    
#     def test_epoch_end(self, outputs):
#         self.evaluation_epoch_end(outputs, "test")

#     def configure_optimizers(self):
#         optimizer = torch.optim.Adam(
#             self.parameters(),
#             lr=self.hparams.lr,
#         )
#         scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
#         return [optimizer], [scheduler]

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# train_dataset = FullDataset(train_x, train_y)
# val_dataset = FullDataset(val_x, val_y)

# train_dataloader = torch.utils.data.DataLoader(
#     train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
# val_dataloader = torch.utils.data.DataLoader(
#     val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

# early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

# trainer = Trainer(
#     progress_bar_refresh_rate=1,
#     log_every_n_steps=1,
#     max_epochs=30,
#     gpus=-1,
#     accelerator='dp',
#     logger=TensorBoardLogger("lightning_logs/", name="resnet"),
#     callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
#     checkpoint_callback=True,
# )

# trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
38/16:
import shap

background = val_x[:100]
test_images = val_x[100:103]
38/17:
e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
38/18:
import shap

background = val_x[:100]
test_images = val_x[100:103]
38/19:
e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)
38/20:
import eli5

background = val_x[:100]
test_images = val_x[100:103]
38/21:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0]
pred = model(img)
38/22:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0]
pred = model([img])
38/23:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model(img)
38/24:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model(img)
print(pred)
38/25:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
38/26:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
eli5.show_prediction(model, pred)
38/27:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
eli5.show_prediction(model, pred, image=img)
38/28:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
eli5.show_prediction(model, img, image=img)
38/29:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
eli5.show_prediction(model, img, image=img)
39/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
39/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
39/3:
print(list(coords_error))
print(imgs.shape)
39/4: coords_error.hist('error')
39/5: coords_error['failure'] = coords_error['error'] > 70
39/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
39/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
39/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
39/9: coords_error.boxplot('nsr', by='failure')
39/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
39/11:
from experiments.dataset_classifier import load_discriminator
import tensorflow as tf
39/12:
from sklearn.model_selection import train_test_split
SEED = 42
model = load_discriminator()
model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6),metrics=['accuracy'])

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED)
39/13:
import torchvision
from torch import nn
import torch
import torch.optim as optim

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/14:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=batch_size,
                                          shuffle=True, num_workers=2, seed=SEED)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=batch_size,
                                          shuffle=True, num_workers=2, seed=SEED)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/15:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2, seed=SEED)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2, seed=SEED)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/16:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/17:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/18:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/19:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)

trainloader = torch.utils.data.DataLoader((train_x, train_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

valloader = torch.utils.data.DataLoader((val_x, val_y), batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/20:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)

trainloader = torch.utils.data.DataLoader(train_x, train_y, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

valloader = torch.utils.data.DataLoader(val_x, val_y, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/21:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)

train_dataset = Dataset(train_x, train_y)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = Dataset(val_x, val_y)
valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/22:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/23:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/24:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/25:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
valloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

model = create_model(2)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/26:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self)
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss

trainer = Trainer()
model = create_model(2)

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/27:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss

trainer = Trainer()
model = create_model(2)

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/28:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss

trainer = Trainer()
model = create_model(2)

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/29:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss

trainer = Trainer()
model = LitModule()

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/30:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/31:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return f.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/32:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/33:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()
train_loader = train_loader.float()

trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/34:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images)).astype(float)
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/35:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images)).astype(float)
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(type(logits))
        print(type(y))
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/36:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images)).astype(float)
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print((logits.dtype))
        print(y.dtype)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/37:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images)).astype(float)
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1).astype(float)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print((logits.dtype))
        print(y.dtype)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/38:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1)

all_images = all_images.astype(np.float32)
labels = labels.astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print((logits.dtype))
        print(y.dtype)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
39/39:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
39/40:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
39/41:
import eli5

background = val_x[:100]
test_images = val_x[100:103]

img = background[0:1]
pred = model.predict(img)
print(pred)
eli5.show_prediction(model, img, image=img)
39/42:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
40/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
40/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
40/3:
print(list(coords_error))
print(imgs.shape)
40/4: coords_error.hist('error')
40/5: coords_error['failure'] = coords_error['error'] > 70
40/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
40/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
40/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
40/9: coords_error.boxplot('nsr', by='failure')
40/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
40/11:
import torchvision
from torch import nn
import torch
import torch.optim as optim
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from pytorch_lightning.core.lightning import LightningModule
from torch.nn import functional as F
from pytorch_lightning import Trainer
from torch.optim import Adam

SEED = 42
BATCH_SIZE=1000

all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

all_images = np.moveaxis(all_images, 3, 1)

all_images = all_images.astype(np.float32)
labels = labels.astype(np.float32)
train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

print(train_x.shape)
print(val_x.shape)
print(train_y.shape)
print(val_y.shape)


class CustomImageDataset(Dataset):
    def __init__(self, imgs, labels):
        self.imgs = imgs
        self.labels = labels

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        return self.imgs[idx], self.labels[idx]
        
train_dataset = CustomImageDataset(train_x, train_y)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

val_dataset = CustomImageDataset(val_x, val_y)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=2)

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class LitModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.model = create_model(2)
    
    def forward(self, x):
        x = self.model(x)
        return F.log_softmax(x, dim=1)
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print((logits.dtype))
        print(y.dtype)
        loss = F.nll_loss(logits, y)
        return loss
    def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)

trainer = Trainer()
model = LitModule()

model = model.float()


trainer.fit(model, train_loader)


for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
41/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
41/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
41/3:
print(list(coords_error))
print(imgs.shape)
41/4: coords_error.hist('error')
41/5: coords_error['failure'] = coords_error['error'] > 70
41/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
41/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
41/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
41/9: coords_error.boxplot('nsr', by='failure')
41/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
41/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
41/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
43/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
43/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
43/3:
print(list(coords_error))
print(imgs.shape)
43/4: coords_error.hist('error')
43/5: coords_error['failure'] = coords_error['error'] > 70
43/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
43/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
44/1: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
44/2: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
44/3: coords_error.boxplot('nsr', by='failure')
45/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
45/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
45/3:
print(list(coords_error))
print(imgs.shape)
45/4: coords_error.hist('error')
45/5: coords_error['failure'] = coords_error['error'] > 70
45/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
45/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
45/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
45/9: coords_error.boxplot('nsr', by='failure')
45/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
45/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
45/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
45/13:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
45/14:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
45/15:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
46/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
46/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
46/3:
print(list(coords_error))
print(imgs.shape)
46/4: coords_error.hist('error')
46/5: coords_error['failure'] = coords_error['error'] > 70
46/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
46/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
46/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
46/9: coords_error.boxplot('nsr', by='failure')
46/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
46/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
46/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
46/13:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
46/14:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entror(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
48/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
48/3:
print(list(coords_error))
print(imgs.shape)
48/4: coords_error.hist('error')
48/5: coords_error['failure'] = coords_error['error'] > 70
48/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
48/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
48/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
48/9: coords_error.boxplot('nsr', by='failure')
48/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
48/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
48/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entror(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/13:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=5):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/14:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(np.float32)

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/15:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
labels2 = np.concatenate((np.zeris((good_images.shape[0])), np.ones((bad_images.shape[0]))))

labels = np.concatenate((labels, labels2), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/16:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
labels2 = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))

labels = np.concatenate((labels, labels2), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/17:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]
labels2 = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, labels2), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/18:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/19:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/20:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/21:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return F.log_softmax(out, dim=1)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()
        y = y.float()
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/22:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()
        y = y.float()
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/23:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()
        y = y.float()
        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.shape)
        print(y.shape)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/24:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/25:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/26:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

#     def evaluate(self, batch, stage=None):
#         x, y = batch
#         logits = self(x)
#         print(logits.dtype)
#         loss = F.nll_loss(logits, y)
#         preds = torch.argmax(logits, dim=1)
#         micro_acc = accuracy(preds, y, average="micro")
#         macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

#         return {
#             "loss": loss.cpu(), 
#             "micro_acc": micro_acc.cpu(),
#             "macro_acc": macro_acc.cpu(),
#             "preds": preds.cpu(),
#             "labels": y.cpu()
#         }
    
#     def evaluation_epoch_end(self, outputs, stage=None):
#         micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
#         macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
#         loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
#         self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
#         # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
#         # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
#         # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/27:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

#     def evaluate(self, batch, stage=None):
#         x, y = batch
#         logits = self(x)
#         print(logits.dtype)
#         loss = F.nll_loss(logits, y)
#         preds = torch.argmax(logits, dim=1)
#         micro_acc = accuracy(preds, y, average="micro")
#         macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

#         return {
#             "loss": loss.cpu(), 
#             "micro_acc": micro_acc.cpu(),
#             "macro_acc": macro_acc.cpu(),
#             "preds": preds.cpu(),
#             "labels": y.cpu()
#         }
    
#     def evaluation_epoch_end(self, outputs, stage=None):
#         micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
#         macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
#         loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
#         self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
#         # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
#         # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
#         # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
#         # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

#     def validation_step(self, batch, batch_idx):
#         metrics = self.evaluate(batch, "val")
#         return metrics
    
#     def validation_epoch_end(self, outputs):
#         self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.double)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    logger=TensorBoardLogger("lightning_logs/", name="resnet"),
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/28:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
48/29:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)

print(all_images.shape)
print(labels.shape)
return

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
49/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
49/3:
print(list(coords_error))
print(imgs.shape)
49/4: coords_error.hist('error')
49/5: coords_error['failure'] = coords_error['error'] > 70
49/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
49/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
49/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
49/9: coords_error.boxplot('nsr', by='failure')
49/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
49/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
49/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)

print(all_imagesages.shape)
print(labels.shape)
return

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/13:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)

print(all_images.shape)
print(labels.shape)
return

train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/14:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.nll_loss(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.nll_loss(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/15:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/16:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.binary_cross_entropy(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))

labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/17:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        print(logits.dtype)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/18:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy(logits, y)
        preds = torch.argmax(logits, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/19:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/20:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
49/21:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
#         y = torch.argmax(y, dim=1)
#         micro_acc = accuracy(preds, y, average="micro")
#         macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
#             "micro_acc": micro_acc.cpu(),
#             "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
#     callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
51/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
51/3:
print(list(coords_error))
print(imgs.shape)
51/4: coords_error.hist('error')
51/5: coords_error['failure'] = coords_error['error'] > 70
51/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
51/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
51/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
51/9: coords_error.boxplot('nsr', by='failure')
51/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
51/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
51/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
#         y = torch.argmax(y, dim=1)
#         micro_acc = accuracy(preds, y, average="micro")
#         macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
#             "micro_acc": micro_acc.cpu(),
#             "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
#     callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/13:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=NUM_CLASSES)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
#     callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/14:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=2)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
#     callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/15:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=2)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
)
logger = TensorBoardLogger("tb_logs", name="my_model")

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, logger=logger)
51/16:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=2)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback],
    checkpoint_callback=True,
    logger= TensorBoardLogger("tb_logs", name="my_model")
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/17:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=2)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

model_checkpoint = ModelCheckpoint(
    monitor='val_macro_acc',
    mode='max',
    filename='{epoch:02d}-{' + 'val_macro_acc' + ':.3f}',
    save_last=True,
    save_top_k=1,
    dirpath='/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/models/',
)
    
trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback, model_checkpoint],
    checkpoint_callback=True,
    logger= TensorBoardLogger("tb_logs", name="my_model")
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
51/18:
import shap
batch = next(iter(test_loader))
images, _ = batch

background = images[:100]
test_images = images[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
51/19:
import shap
batch = next(iter(val_loader))
images, _ = batch

background = images[:100]
test_images = images[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
51/20:
import shap
batch = next(iter(val_dataloader))
images, _ = batch

background = images[:100]
test_images = images[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
51/21:
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)
shap.image_plot(shap_numpy, -test_numpy)
51/22:
import shap
batch = next(iter(val_dataloader))
images, _ = batch

background = images[:100]
test_images = images[100:103]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
51/23:
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)
shap.image_plot(shap_numpy, -test_numpy)
52/1:
import shap
batch = next(iter(val_dataloader))
images, _ = batch
print(len(val_dataloader))
background = images[:100]
test_images = images[100:120]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
54/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
54/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
54/3:
print(list(coords_error))
print(imgs.shape)
54/4: coords_error.hist('error')
54/5: coords_error['failure'] = coords_error['error'] > 70
54/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
54/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
54/8:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
54/9:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
54/10:
print(list(coords_error))
print(imgs.shape)
54/11: coords_error.hist('error')
54/12: coords_error['failure'] = coords_error['error'] > 70
54/13:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
54/14: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
57/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
57/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
57/3:
print(list(coords_error))
print(imgs.shape)
57/4: coords_error.hist('error')
57/5: coords_error['failure'] = coords_error['error'] > 70
57/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
57/7: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
57/8: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
57/9: coords_error.boxplot('nsr', by='failure')
57/10:
all_images = np.concatenate((good_images, bad_images))
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))
57/11:
# import torchvision
# from torch import nn
# import torch
# import torch.optim as optim
# from sklearn.model_selection import train_test_split
# from torch.utils.data import Dataset
# from pytorch_lightning.core.lightning import LightningModule
# from torch.nn import functional as F
# from pytorch_lightning import Trainer
# from torch.optim import Adam

# SEED = 42
# BATCH_SIZE=1000

# all_images = np.concatenate((good_images, bad_images))
# labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0])))).astype(float)

# all_images = np.moveaxis(all_images, 3, 1)

# all_images = all_images.astype(np.float32)
# labels = labels.astype(np.float32)
# train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

# print(train_x.shape)
# print(val_x.shape)
# print(train_y.shape)
# print(val_y.shape)


# class CustomImageDataset(Dataset):
#     def __init__(self, imgs, labels):
#         self.imgs = imgs
#         self.labels = labels

#     def __len__(self):
#         return len(self.imgs)

#     def __getitem__(self, idx):
#         return self.imgs[idx], self.labels[idx]
        
# train_dataset = CustomImageDataset(train_x, train_y)
# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# val_dataset = CustomImageDataset(val_x, val_y)
# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,
#                                           shuffle=True, num_workers=2)

# def create_model(num_classes):
#     model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
#     model.maxpool = nn.Identity()
#     return model

# class LitModule(LightningModule):
#     def __init__(self):
#         super().__init__()
#         self.model = create_model(2)
    
#     def forward(self, x):
#         x = self.model(x)
#         return F.log_softmax(x, dim=1)
    
#     def training_step(self, batch, batch_idx):
#         x, y = batch
#         logits = self(x)
#         print((logits.dtype))
#         print(y.dtype)
#         loss = F.nll_loss(logits, y)
#         return loss
#     def configure_optimizers(self):
#         return Adam(self.parameters(), lr=1e-3)

# trainer = Trainer()
# model = LitModule()

# model = model.float()


# trainer.fit(model, train_loader)


# for epoch in range(2):  # loop over the dataset multiple times

#     running_loss = 0.0
#     for i, data in enumerate(train_loader, 0):
#         # get the inputs; data is a list of [inputs, labels]
#         inputs, labels = data

#         # zero the parameter gradients
#         optimizer.zero_grad()

#         # forward + backward + optimize
#         outputs = model(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()

#         # print statistics
#         running_loss += loss.item()
#         if i % 2000 == 1999:    # print every 2000 mini-batches
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0
57/12:
import torch
from torch import nn
import torchvision
import torch.optim as optim
from sklearn.model_selection import train_test_split

from torch.nn import functional as F
from pytorch_lightning import LightningModule, Trainer, seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from torch.optim.lr_scheduler import MultiStepLR
from torch.optim.swa_utils import AveragedModel, update_bn
from torchmetrics.functional import accuracy, confusion_matrix
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef
from torch.utils.data import Dataset

SEED = 42
BATCH_SIZE=1000

def create_model(num_classes):
    model = torchvision.models.resnet18(pretrained=False, num_classes=num_classes)
    model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    model.maxpool = nn.Identity()
    return model

class FullDataset(Dataset):
    """Basic class encapulating dataset functions, for use with dataloader."""

    def __init__(self, img_numpy_array: np.ndarray, labels_numpy_array: np.ndarray) -> None:
        """Initialise with numpy array."""
        self.img_data = img_numpy_array
        self.labels = torch.from_numpy(labels_numpy_array)
        print("Array shape loaded into torch dataset:", self.img_data.shape)

    def __len__(self) -> int:
        """Return length of dataset."""
        assert self.img_data.shape[0] == self.labels.shape[0]
        return self.img_data.shape[0]

    def __getitem__(self, idx) -> torch.Tensor:
        """Return items from dataset as torch tensors."""
        img_data_selection = self.img_data[idx]
        img_tensor = torch.from_numpy(img_data_selection).float()
        return (img_tensor, self.labels[idx])


class LitResnet(LightningModule):
    def __init__(self, lr=0.05, train_dataset_len=640, num_classes=2):
        super().__init__()

        self.save_hyperparameters()
        self.model = create_model(num_classes)
        
        self.train_dataset_len = train_dataset_len

    def forward(self, x):
        out = self.model(x)
        return out

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x).float()

        loss = F.binary_cross_entropy_with_logits(logits, y)
        self.log("train_loss", loss, prog_bar=True)
        return loss

    def evaluate(self, batch, stage=None):
        x, y = batch
        logits = self(x)
        loss = F.binary_cross_entropy_with_logits(logits, y)
        preds = torch.argmax(logits, dim=1)
        y = torch.argmax(y, dim=1)
        micro_acc = accuracy(preds, y, average="micro")
        macro_acc = accuracy(preds, y, average="macro", num_classes=2)

        return {
            "loss": loss.cpu(), 
            "micro_acc": micro_acc.cpu(),
            "macro_acc": macro_acc.cpu(),
            "preds": preds.cpu(),
            "labels": y.cpu()
        }
    
    def evaluation_epoch_end(self, outputs, stage=None):
        micro_acc = torch.stack([tmp[f"micro_acc"] for tmp in outputs]).mean()
        macro_acc = torch.stack([tmp[f"macro_acc"] for tmp in outputs]).mean()
        loss = torch.stack([tmp[f"loss"] for tmp in outputs]).mean()
        self.log_dict({f"{stage}_micro_acc": micro_acc, f"{stage}_macro_acc": macro_acc, f"{stage}_loss": loss}, logger=True, prog_bar=True)
        
        # preds = torch.cat([tmp[f"preds"] for tmp in outputs])
        # labels = torch.cat([tmp[f"labels"] for tmp in outputs])
        
        # conf_mat = confusion_matrix(preds, labels, num_classes=NUM_CLASSES)
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/preds.npy", preds.detach().numpy())
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/labels.npy", labels.detach().numpy())
        
        # np.save("/camp/project/proj-data-challenge/2021/Project1-El-Oakley/scripts/models/run-2/conf_mat.npy", conf_mat.numpy())
        
        

    def validation_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "val")
        return metrics
    
    def validation_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "val")

    def test_step(self, batch, batch_idx):
        metrics = self.evaluate(batch, "test")
        return metrics
    
    def test_epoch_end(self, outputs):
        self.evaluation_epoch_end(outputs, "test")

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(
            self.parameters(),
            lr=self.hparams.lr,
        )
        scheduler = MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.1)
        return [optimizer], [scheduler]

all_images = np.concatenate((good_images, bad_images))
all_images = np.moveaxis(all_images, 3, 1).astype(np.float32)

opp_labels = np.concatenate((np.zeros((good_images.shape[0])), np.ones((bad_images.shape[0]))))[:, np.newaxis]
labels = np.concatenate((np.ones((good_images.shape[0])), np.zeros((bad_images.shape[0]))))[:, np.newaxis]

labels = np.concatenate((labels, opp_labels), axis=1)
labels = labels.astype(np.float32)


train_x, val_x, train_y, val_y = train_test_split(all_images, labels, test_size=0.3, stratify=labels, shuffle=True, random_state=SEED) 

train_dataset = FullDataset(train_x, train_y)
val_dataset = FullDataset(val_x, val_y)

train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)
val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)

early_stop_callback = EarlyStopping(monitor='val_macro_acc', patience=6, mode='max')

model_checkpoint = ModelCheckpoint(
    monitor='val_macro_acc',
    mode='max',
    filename='{epoch:02d}-{' + 'val_macro_acc' + ':.3f}',
    save_last=True,
    save_top_k=1,
    dirpath='/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/models/',
)
    
trainer = Trainer(
    progress_bar_refresh_rate=1,
    log_every_n_steps=1,
    max_epochs=30,
    gpus=-1,
    accelerator='dp',
    callbacks=[LearningRateMonitor(logging_interval="step"), early_stop_callback, model_checkpoint],
    checkpoint_callback=True,
    logger= TensorBoardLogger("tb_logs", name="my_model")
)

model = LitResnet()
trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)
57/13:
import shap
batch = next(iter(val_dataloader))
images, _ = batch
print(len(val_dataloader))
background = images[:100]
test_images = images[100:120]

e = shap.DeepExplainer(model, background)
shap_values = e.shap_values(test_images)
57/14:
shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)
shap.image_plot(shap_numpy, -test_numpy)
58/1: good_images_random_idx = np.random.sample(list(range(good_images.shape[0])), size=10, replace=False)
58/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
58/3:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
58/4:
print(list(coords_error))
print(imgs.shape)
58/5: coords_error.hist('error')
58/6: coords_error['failure'] = coords_error['error'] > 70
58/7:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
58/8: good_images_random_idx = np.random.sample(list(range(good_images.shape[0])), size=10, replace=False)
58/9: good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=10, replace=False)
58/10:
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=10, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=10, replace=False)
58/11:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=1)
show_psf_axial(good_images_random)
59/1:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=1)
show_psf_axial(good_images_random)
59/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
59/3:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
59/4:
print(list(coords_error))
print(imgs.shape)
59/5: coords_error.hist('error')
59/6: coords_error['failure'] = coords_error['error'] > 70
59/7:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
59/8:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=1)
show_psf_axial(good_images_random)
60/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
60/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
60/3:
print(list(coords_error))
print(imgs.shape)
60/4: coords_error.hist('error')
60/5: coords_error['failure'] = coords_error['error'] > 70
60/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
60/7:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=1)
show_psf_axial(good_images_random)
60/8:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=1)
print(good_images_random.shape)
show_psf_axial(good_images_random)
60/9:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=0)
print(good_images_random.shape)
show_psf_axial(good_images_random)
60/10:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=0)

plt.imshow(good_images_random)
plt.show()
60/11:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()
61/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
61/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
61/3:
print(list(coords_error))
print(imgs.shape)
61/4: coords_error.hist('error')
61/5: coords_error['failure'] = coords_error['error'] > 70
61/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
61/7:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from data
good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()
61/8:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in chunks(good_images_random, n_cols)])

plt.imshow(good_images_random)
plt.show()
62/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
62/2:
coords_error = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/coords.csv')
imgs = np.load('/home/miguel/Projects/uni/phd/smlm_z/final_project/smlm_3d/tmp/imgs.npy')
62/3:
print(list(coords_error))
print(imgs.shape)
62/4: coords_error.hist('error')
62/5: coords_error['failure'] = coords_error['error'] > 70
62/6:
good_images_idx = np.where(coords_error['failure'])[0]
bad_images_idx = np.where(~coords_error['failure'])[0]
good_images = imgs[good_images_idx]
bad_images = imgs[bad_images_idx]
print(good_images.shape)
print(bad_images.shape)
62/7:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in chunks(good_images_random, n_cols)])

plt.imshow(good_images_random)
plt.show()
62/8:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in chunks(list(good_images_random), n_cols)])

plt.imshow(good_images_random)
plt.show()
62/9:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

print(good_images_random.shape)
n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in chunks(good_images_random, n_cols)])

plt.imshow(good_images_random)
plt.show()
62/10:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks


n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in list(chunks(good_images_random, n_cols)])

plt.imshow(good_images_random)
plt.show()
62/11:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks


n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(c, axis=1) for c in list(chunks(good_images_random, n_cols))])

plt.imshow(good_images_random)
plt.show()
62/12:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks


n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(good_images_random[i*n_cols:(i+1)*n_cols, axis=1) for i in range(0, len(good_images_random)-n_cols)])

plt.imshow(good_images_random)
plt.show()
62/13:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks


n_cols = np.sqrt(n_images)
good_images_random = np.concatenate([np.concatenate(good_images_random[i*n_cols:(i+1)*n_cols], axis=1) for i in range(0, len(good_images_random)-n_cols)])

plt.imshow(good_images_random)
plt.show()
62/14:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks


n_cols = np.sqrt(n_images)

plt.imshow(good_images_random)
plt.show()
62/15:
n_images = 100
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

n_cols = np.sqrt(n_images)
good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()
62/16:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

n_cols = np.sqrt(n_images)
good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()
62/17:
n_images = 10
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/18:
df.plot('x', 'error')
plt.show()
df.plot('y', 'error')
plt.show()
62/19:
coords_error.plot('x', 'error')
plt.show()
coords_error.plot('y', 'error')
plt.show()
62/20:
coords_error.scatter('x', 'error')
plt.show()
coords_error.scatter('y', 'error')
plt.show()
62/21:
coords_error.plot.scatter('x', 'error')
plt.show()
coords_error.plot.scatter('y', 'error')
plt.show()
62/22:
n_images = 10
print(good_images.shape)
print(bad_images.shape)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/23:
n_images = 10
print(good_images.shape[0]/199)
print(bad_images.shape/199)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/24:
n_images = 10
print(good_images.shape[0]/199)
print(bad_images.shape[0]/199)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/25:
n_images = 10
print(good_images.shape[0]/200)
print(bad_images.shape[0]/200)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/26:
n_images = 10
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/27:
print(list(coords_error))
print(imgs.shape)
coords_error.plot('error')
plt.show()
62/28:
print(list(coords_error))
print(imgs.shape)
coords_error.plot('Unnamed: 0', 'error')
plt.show()
62/29:
print(list(coords_error))
print(imgs.shape)
62/30:
coords_error.boxplot('nsr', by='failure')
plt.xlabel('Predicted z position within 50nm')
62/31: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
62/32: coords_error['nsr'] = list(map(estimate_nsr_ratio, imgs))
62/33:
coords_error.boxplot('nsr', by='failure')
plt.xlabel('Predicted z position within 50nm')
62/34:
coords_error.plot.scatter('x', 'error')
plt.show()
coords_error.plot.scatter('y', 'error')
plt.show()
coords_error.plot.scatter('x', 'y', c='error')
plt.show()
62/35:

coords_error.groupby(['x', 'y']).plot.scatter('x', 'y', c='error')
plt.show()
62/36:
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], columns=['x', 'y'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/37:
stack_errors = pd.pivot_table(coords_error, values='error', index=['x'], columns=['x', 'y'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/38:
stack_errors = pd.pivot_table(coords_error, values='error', index=['x'], columns=['x'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/39:
print(list(stack_errors))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x'], columns=['x'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/40:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x'], columns=['x'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/41:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/42:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', columns=['x', 'y'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')
plt.show()
62/43:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', columns=['x', 'y'], aggfunc=np.sum)
print(stack_errors)

plt.show()
62/44:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.sum)
print(stack_errors)

plt.show()
62/45:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.sum)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/46:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/47:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', columns=['x', 'y'], aggfunc=np.mean)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/48:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
print(list(stack_errors))
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/49:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values=['x', 'y', 'error'], index=['x', 'y'], aggfunc=np.mean)
print(list(stack_errors))
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/50:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
print(list(stack_errors))
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/51:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
print(stack_errors)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/52:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
print(stack_errors.index)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/53:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', columns=['x', 'y', 'error'], index=['x', 'y'], aggfunc=np.mean)
print(stack_errors.index)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/54:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', columns=['x', 'y'], index=['x', 'y'], aggfunc=np.mean)
print(stack_errors.index)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/55:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
print(stack_errors.index)
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/56:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

plt.scatter(xs, ys, c=stack_errors['error'])
# stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/57:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

stack_errors = pd.DataFrame.from_dict({'x': xs, 'y': ys, 'error': stack_errors['error']})
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/58:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

stack_errors = pd.DataFrame.from_dict({'x': xs, 'y': ys, 'error': np.log(stack_errors['error'])})
stack_errors.plot.scatter('x', 'y', c='error')

plt.show()
62/59:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

stack_errors = pd.DataFrame.from_dict({'x': xs, 'y': ys, 'log_mean_error': np.log(stack_errors['error'])})
stack_errors.plot.scatter('x', 'y', c='log_mean_error')

plt.show()
62/60:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

stack_errors = pd.DataFrame.from_dict({'x': xs, 'y': ys, 'log_mean_error': np.log(stack_errors['error'])})
stack_errors.plot.scatter('x', 'y', c='log_mean_error')

plt.xlabel('x')
plt.show()
62/61:
print(list(coords_error))
stack_errors = pd.pivot_table(coords_error, values='error', index=['x', 'y'], aggfunc=np.mean)
xs = [x[0] for x in stack_errors.index]
ys = [x[1] for x in stack_errors.index]

stack_errors = pd.DataFrame.from_dict({'x': xs, 'y': ys, 'log_mean_error': np.log(stack_errors['error'])})
stack_errors.plot.scatter('x', 'y', c='log_mean_error', xlabel='x')

plt.xlabel('x')
plt.show()
62/62:
n_images = 10
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=0)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/63:
n_images = 10
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=1)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=0)
plt.imshow(bad_images_random)
plt.show()
62/64:
n_images = 10
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=1)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=1)
plt.imshow(bad_images_random)
plt.show()
62/65:
n_images = 10
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=1)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=1)
plt.imshow(bad_images_random)
plt.show()
62/66: from experiments.noise.signal_noise_ratio import estimate_nsr_ratio
62/67:
im_coords = set([f'{x}_{y}' for x,y in zip(coords_error['x'], coords_error['y'])])
print(im_coords)
print(good_images.shape[0]/201)
print(bad_images.shape[0]/201)
good_images_random_idx = np.random.choice(list(range(good_images.shape[0])), size=n_images, replace=False)
bad_images_random_idx = np.random.choice(list(range(bad_images.shape[0])), size=n_images, replace=False)

good_images_random = good_images[good_images_random_idx].squeeze()
bad_images_random = bad_images[bad_images_random_idx].squeeze()

from data.visualise import show_psf_axial
from util import chunks

good_images_random = np.concatenate(good_images_random, axis=1)
plt.imshow(good_images_random)
plt.show()


bad_images_random = np.concatenate(bad_images_random, axis=1)
plt.imshow(bad_images_random)
plt.show()
62/68: print(coords_error['x'])
62/69:
idx_steps = [i for i in list(range(len(coords_error['x']))) if x[i]!=x[i+1]]
print(idx_steps)
62/70:
idx_steps = [i for i in list(range(len(coords_error['x']))) if coords_error['x'][i]!=coords_error['x'][i+1]]
print(idx_steps)
62/71:
idx_steps = [i for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
print(idx_steps)
62/72:
idx_steps = [i//198 for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
print(idx_steps)
62/73:
idx_steps = [(i+1)//199 for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
print(idx_steps)
62/74:
idx_steps = [i for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
print(idx_steps)
62/75:
idx_steps = [i for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
chunked_psfs = [imgs[idx_steps[i]:idx_steps[i+1]] for i in list(range(len(idx_steps)-1))]
62/76:
idx_steps = [i for i in list(range(len(coords_error['x'])-1)) if coords_error['x'][i]!=coords_error['x'][i+1]]
chunked_psfs = [imgs[idx_steps[i]:idx_steps[i+1]] for i in list(range(len(idx_steps)-1))]
for i in chunked_psfs:
    print(i.shape)
64/1:
import pandas as pd
import numpy as np
64/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
64/3:
df = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_segmentation/src/data/test_0.csv')
print(df)
df.plot.scatter('x', 'y', c='clusterID')
64/4:
df = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_segmentation/src/data/test_0.csv')
df['clusterID'] = str(df['clusterID'])
df.plot.scatter('x', 'y', c='clusterID')
64/5:
df = pd.read_csv('/home/miguel/Projects/uni/phd/smlm_segmentation/src/data/test_0.csv')
df['clusterID'] = df['clusterID'].astype(str)
df.plot.scatter('x', 'y', c='clusterID')
64/6: np.random.normal(5, 3)
64/7: np.random.normal(5, 3)
64/8:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
64/9:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
64/10:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd =
64/11:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
64/12:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='')
64/13:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
64/14:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='')
65/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
65/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='')
65/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
65/4:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='')
66/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from src.data_sim.gen_data import ClusterDataset
66/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='')
66/3:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.scatter('x', 'y', c='clusterID')
66/4:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

cd.df.plot.scatter('x', 'y', c='clusterID')
66/5:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
66/6:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
print(set(df['clusterID']))
plt.scatter(df['x'], df['y'], c=df['clusterID'])
66/7:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
66/8:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
66/9:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
plt.legend()
66/10:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
66/11: from functools import partial
66/12:
from functools import partial

coords = df[['x', 'y']].numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply(func, coords, axis=1)
66/13:
from functools import partial

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply(func, coords, axis=1)
66/14:
from functools import partial

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, coords, axis=1)
66/15:
from functools import partial

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, coords)
66/16:
from functools import partial

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords)
66/17:
from functools import partial

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(target_point.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/18:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/19:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    distances = cdict(points, target_point)
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/20:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    distances = cdist(points, target_point)
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/21:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/22:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(points.shape)
    print(taget_point.shape)
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/23:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    print(points.shape)
    print(target_point.shape)
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/24:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_points = target_point[:, np.newaxis]
    print(points.shape)
    print(target_point.shape)
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/25:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[:, np.newaxis]
    print(points.shape)
    print(target_point.shape)
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/26:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    print(points.shape)
    print(target_point.shape)
    distances = cdist(points, target_point[:, np.newaxis])
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/27:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    print(points.shape)
    print(target_point.shape)
    distances = cdist(points, target_point)
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/28:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    print(distances.shape)

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/29:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)
66/30:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    temp = 1/log(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/31:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()

def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    temp = 1/np.log(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/32:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/np.log(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/33:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 8


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/np.log(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/34:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 8


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/35:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df.plot.scatter('x', 'y', c='temp')
66/36:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
66/37:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
df.plot.scatter('x', 'y', c='temp')
67/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
67/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
67/3:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
67/4:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
df.plot.scatter('x', 'y', c='temp')
67/5: def raster_img(df, voxel_size, img_shape):
68/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
68/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
68/3:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
68/4:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
df.plot.scatter('x', 'y', c='temp')
68/5:
def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    
    

img = raster_img(df, 100, (2000, 2000))
68/6:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
plt.gca().set_aspect('equal', adjustable='box')
df.plot.scatter('x', 'y', c='temp')
68/7:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
plt = df.plot.scatter('x', 'y', c='temp')
plt.gca().set_aspect('equal', adjustable='box')
68/8:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
plt = df.plot.scatter('x', 'y', c='temp')
plt.set_aspect('equal', adjustable='box')
68/9:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
plt = df.plot.scatter('x', 'y', c='temp')
plt.set_aspect('equal')
68/10:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)


def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    
    
kern = gkern()
print(kern)
img = raster_img(df, 100, (2000, 2000))
68/11:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)


def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    for i in df.shape[0]:
        row = df.iloc[i]
        print(row)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/12:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)


def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        row = df.iloc[i]
        print(row)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/13:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)


def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        row = dict(df.iloc[i])
        print(row)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/14:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)


def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    print(img.dtype)
    for i in range(df.shape[0]):
        row = dict(df.iloc[i])
        i_kernel = kernel * temp
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/15:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel, coords):
    center_voxel = coords / voxel_size

def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    print(img.dtype)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        i_kernel = kernel * point['temp']
        coords = np.array([point['x'], point['y']])
        voxel_corner = coord_to_corner_voxel(voxel_size, kernel, coords)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/16:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel, coords):
    center_voxel = coords / voxel_size
    print(center_voxel)

def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    print(img.dtype)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        i_kernel = kernel * point['temp']
        coords = np.array([point['x'], point['y']])
        voxel_corner = coord_to_corner_voxel(voxel_size, kernel, coords)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/17:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel, coords):
    center_voxel = coords // voxel_size
    print(center_voxel)

def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    print(img.dtype)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        i_kernel = kernel * point['temp']
        coords = np.array([point['x'], point['y']])
        voxel_corner = coord_to_corner_voxel(voxel_size, kernel, coords)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/18:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel, coords):
    center_voxel = coords // voxel_size
    center_voxel = kernel.shape[0]

def raster_img(df, voxel_size, img_shape, kernel):
    img = np.zeros(img_shape)
    print(img.dtype)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        i_kernel = kernel * point['temp']
        coords = np.array([point['x'], point['y']])
        voxel_corner = coord_to_corner_voxel(voxel_size, kernel, coords)
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
68/19:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return center_voxel - kernel_dim]

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        img[x:x+kernel_dim, y:y+kernel_dim] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
68/20:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return center_voxel - kernel_dim

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        img[x:x+kernel_dim, y:y+kernel_dim] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
68/21:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return center_voxel - kernel_dim

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        print(x, x+kernel_dim)
        img[x:x+kernel_dim, y:y+kernel_dim] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
68/22:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        img[x:x+kernel_dim, y:y+kernel_dim] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
68/23:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        print(x, y)
        img[x:x+kernel_dim, y:y+kernel_dim] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
68/24:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
69/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
69/3:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
69/4:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
69/5:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/6:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = img / img.max()
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/7:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = img / img.max()
    print(img.min(), img.max())
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/8:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max() * (255 * 255)
    
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/9:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/10:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
69/11:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
69/12:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
69/13:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
69/14:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
plt.imshow(img)
plt.show()
69/15:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
imshow(img)
plt.show()
69/16:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)


IMG_PADDING_PIXELS = 10
def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
    
    
kernel = gkern()

img = raster_img(df, 100, (2000, 2000), kernel)
imshow(img)
plt.show()
69/17:
def gkern(l=5, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 10
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/18:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 10
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/19:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/20:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.max(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/21:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.max(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (250, 2000), kernel)
imshow(img)
plt.show()
69/22:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.max(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 250), kernel)
imshow(img)
plt.show()
69/23:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
69/24:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 10000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
69/25:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
69/26:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
69/27:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.max(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/28:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 500), kernel)
imshow(img)
plt.show()
69/29:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max()) * (255 * 255)
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 1000), kernel)
imshow(img)
plt.show()
69/30:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 1000), kernel)
imshow(img)
plt.show()
69/31:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (2000, 2000), kernel)
imshow(img)
plt.show()
69/32:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 1000), kernel)
imshow(img)
plt.show()
69/33:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 6000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
69/34:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
69/35:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
69/36:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 1000), kernel)
imshow(img)
plt.show()
69/37:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 400), kernel)
imshow(img)
plt.show()
69/38:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (400, 1000), kernel)
imshow(img)
plt.show()
69/39:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (800, 1000), kernel)
imshow(img)
plt.show()
69/40:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[y_start:y_end, x_start:x_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (800, 1000), kernel)
imshow(img)
plt.show()
69/41:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (800, 1000), kernel)
imshow(img)
plt.show()
69/42:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 400), kernel)
imshow(img)
plt.show()
69/43:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[1]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 400), kernel)
imshow(img)
plt.show()
69/44:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[1]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 400), kernel)
imshow(img)
plt.show()
69/45:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 10, (1000, 400), kernel)
imshow(img)
plt.show()
69/46:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (320, 320), kernel)
imshow(img)
plt.show()
69/47:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 320), kernel)
imshow(img)
plt.show()
69/48:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 150), kernel)
imshow(img)
plt.show()
69/49:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (0, 150), kernel)
imshow(img)
plt.show()
69/50:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (300, 150), kernel)
imshow(img)
plt.show()
69/51:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 150), kernel)
imshow(img)
plt.show()
69/52:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (250, 150), kernel)
imshow(img)
plt.show()
69/53:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (200, 150), kernel)
imshow(img)
plt.show()
69/54:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 150), kernel)
imshow(img)
plt.show()
69/55:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[0] or x_start < 0 or x_end >= img_shape[1]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 150), kernel)
imshow(img)
plt.show()
69/56:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (150, 150), kernel)
imshow(img)
plt.show()
69/57:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (250, 150), kernel)
imshow(img)
plt.show()
69/58:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (250, 250), kernel)
imshow(img)
plt.show()
69/59:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (200, 250), kernel)
imshow(img)
plt.show()
69/60:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (100, 250), kernel)
imshow(img)
plt.show()
69/61:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

img = raster_img(df, 100, (300, 250), kernel)
imshow(img)
plt.show()
70/1:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 200,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (300, 250), kernel)
imshow(img)
plt.show()
70/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
70/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/2:
cluster1 = {
    'x': 1000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

cluster2 = {
    'x': 6000,
    'y': 1000,
    'scale': 500,
    'n_points': 1000
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/3:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/4:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
71/5:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 200,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (300, 250), kernel)
imshow(img)
plt.show()
71/6:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 200,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (300, 250), kernel)
imshow(img)
plt.show()
71/7:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 200,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (1000, 1000), kernel)
imshow(img)
plt.show()
71/8:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 500,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (1000, 1000), kernel)
imshow(img)
plt.show()
71/9:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 1000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (1000, 1000), kernel)
imshow(img)
plt.show()
71/10:
def gkern(l=100, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 100, (1000, 1000), kernel)
imshow(img)
plt.show()
71/11:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])


img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/12:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

print(10000//90)
img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/13:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

print(10000//90)
img = raster_img(tmp_df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/14:
cluster1 = {
    'x': 50,
    'y': 50,
    'scale': 50,
    'n_points': 100
}

cluster2 = {
    'x': 50,
    'y': 300,
    'scale': 50,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/15:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/16:
cluster1 = {
    'x': 50,
    'y': 50,
    'scale': 50,
    'n_points': 100
}

cluster2 = {
    'x': 300,
    'y': 50,
    'scale': 50,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/17:
cluster1 = {
    'x': 50,
    'y': 50,
    'scale': 25,
    'n_points': 100
}

cluster2 = {
    'x': 300,
    'y': 50,
    'scale': 25,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/18:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/19:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
scatter_plot.set_aspect('equal')
71/20:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/21:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return np.ones((l, l))
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/22:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/23:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/24:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/25:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 25,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 25,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/26:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/27:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/28:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (320, 320), kernel)
imshow(img)
plt.show()
71/29:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/30:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 50,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 50,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/31:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/32:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/33:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/34:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/35:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/36:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/37:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/38:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 5000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/39:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/40:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/41:
def gkern(l=25, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/42:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/43:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 100
    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/44:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
KERNEL_DIM = 50
kernel = gkern(KERNEL_DIM)

IMG_PADDING_PIXELS = KERNEL_DIM // 2
IMG_DIM_PIXELS = (120, 120)    

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/45:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
KERNEL_DIM = 50
kernel = gkern(KERNEL_DIM)

IMG_PADDING_PIXELS = int(KERNEL_DIM // 2)
IMG_DIM_PIXELS = (120, 120)    

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/46:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
KERNEL_DIM = 50
kernel = gkern(KERNEL_DIM)

IMG_PADDING_PIXELS = 0
IMG_DIM_PIXELS = (120, 120)    

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/47:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (120, 120)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/48:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/49:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 5000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/50:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/51:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/52:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (120, 120)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/53:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (120, 120)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/54:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/55:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 5000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/56:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/57:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/58:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (120, 120)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/59:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/60:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/61:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 0
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (120, 120), kernel)
imshow(img)
plt.show()
71/62:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_PADDING_PIXELS = 0
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/63:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/64:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/65:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/66:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/67:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/68:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

cluster2 = {
    'x': 2000,
    'y': 500,
    'scale': 250,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/69:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/70:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/71:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 2


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/72:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/73:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = 1/sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

# df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/74:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/75:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = np.exp(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/76:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = np.exp(np.e, sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/77:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = np.exp(10, sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/78: np.exp(2,2)
71/79: np.exp(2)
71/80:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = np.exp(sum(distances))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/81:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = np.exp(np.log(sum(distances)))
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/82:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/83:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (1000, 1000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/84:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 100,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/85:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 1000,
     'y': 1000,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 10000,
     'y': 1000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/86:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 10000,
     'y': 10000,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/87:
def gkern(l=10, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(tmp_df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/88:
def gkern(l=10, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/89:
def gkern(l=1, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (1000, 1000), kernel)
imshow(img)
plt.show()
71/90:
def gkern(l=10, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (10000, 10000)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, (240, 240), kernel)
imshow(img)
plt.show()
71/91:
def gkern(l=10, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/92:
def gkern(l=50, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/93:
def gkern(l=24, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
    
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

tmp_df = pd.DataFrame.from_records([
    {'x': 100,
     'y': 100,
     'clusterID': 0,
     'temp': 1
    }, 
    {'x': 100000,
     'y': 10000,
     'clusterID': 1,
     'temp': 0.5}
])

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/94:
def gkern(l=24, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 0
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/95:
def gkern(l=24, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/96:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
71/97:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 100,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 100,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
71/98:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
71/99:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/100:
def gkern(l=24, sig=1.):
    """\
    creates gaussian kernel with side length `l` and a sigma of `sig`
    """
    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
    kernel = np.outer(gauss, gauss)
    return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, kernel_dim, coords):
    center_voxel = coords // voxel_size
    return (center_voxel - kernel_dim).astype(int)

def raster_img(df, voxel_size, img_shape, kernel):
    kernel_dim = kernel.shape[0]
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, kernel_dim, coords)
        
        i_kernel = kernel * point['temp']
        x_start = x+IMG_PADDING_PIXELS
        x_end = x_start+kernel_dim
        
        y_start = y+IMG_PADDING_PIXELS
        y_end = y_start + kernel_dim
        if y_start < 0 or y_end >= img_shape[1] or x_start < 0 or x_end >= img_shape[0]:
            print(x_start, x_end, y_start, y_end, ' is out of bounds')
            continue
        img[x_start:x_end, y_start:y_end] += i_kernel
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/101:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS, kernel)
imshow(img)
plt.show()
71/102:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/103:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        print(x, y)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/104:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
71/105:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        print(x, y)
        img[pixel_coords] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/106:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        img[pixel_coords] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/107:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        img[pixel_coords] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/108:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        img[[pixel_coords]] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (240, 240)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/109:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        img[[pixel_coords]] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (500, 500)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/110:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        img[[pixel_coords]] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/111:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        pixel_coords = coord_to_corner_voxel(voxel_size, coords)
        print(pixel_coords)
        img[[pixel_coords]] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
71/112:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
72/2:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 100,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 100,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
72/3:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
72/4:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
72/5:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/6:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/7:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x > img.shape[1] or y > img.shape[0]:
            print(f'{x}, {y} is out of bounds')
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_PADDING_PIXELS = 10
IMG_DIM_PIXELS = (200, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/8:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x > img.shape[1] or y > img.shape[0]:
            print(f'{x}, {y} is out of bounds')
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (100, 100)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/9:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

cluster2 = {
    'x': 1000,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
72/10:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

cluster2 = {
    'x': 3000,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
72/11:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

cluster2 = {
    'x': 5000,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
72/12:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
72/13:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
72/14:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
72/15:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x > img.shape[1] or y > img.shape[0]:
            print(f'{x}, {y} is out of bounds')
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (100, 100)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/16:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (100, 100)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/17:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (100, 100)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/18:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 240)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/19:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 120)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/20:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (120, 240)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/21:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 240)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/22:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/23:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (100, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/24:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/25:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['x'], point['y']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/26:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())
    
    return img
IMG_DIM_PIXELS = (240, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/27:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)
from scipy.ndimage.filters import gaussian_filter

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())

    blurred = gaussian_filter(img, sigma=7)
    return blurred
IMG_DIM_PIXELS = (240, 200)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
72/28:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)
from scipy.ndimage.filters import gaussian_filter

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())

    blurred = gaussian_filter(img, sigma=7)
    return blurred
IMG_DIM_PIXELS = (240, 240)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
74/1:
import torch.nn as nn
import torch.nn.functional as F

from ..cluster.vgg import VGGTrunk, VGGNet

__all__ = ["SegmentationNet10a"]


# From first iteration of code, based on VGG11:
# https://github.com/xu-ji/unsup/blob/master/mutual_information/networks
# /vggseg.py

class SegmentationNet10aTrunk(VGGTrunk):
  def __init__(self, config, cfg):
    super(SegmentationNet10aTrunk, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    assert (config.input_sz % 2 == 0)

    self.conv_size = 3
    self.pad = 1
    self.cfg = cfg
    self.in_channels = config.in_channels if hasattr(config, 'in_channels') \
      else 3

    self.features = self._make_layers()

  def forward(self, x):
    x = self.features(x)  # do not flatten
    return x


class SegmentationNet10aHead(nn.Module):
  def __init__(self, config, output_k, cfg):
    super(SegmentationNet10aHead, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    self.cfg = cfg
    num_features = self.cfg[-1][0]

    self.num_sub_heads = config.num_sub_heads

    self.heads = nn.ModuleList([nn.Sequential(
      nn.Conv2d(num_features, output_k, kernel_size=1,
                stride=1, dilation=1, padding=1, bias=False),
      nn.Softmax2d()) for _ in xrange(self.num_sub_heads)])

    self.input_sz = config.input_sz

  def forward(self, x):
    results = []
    for i in xrange(self.num_sub_heads):
      x_i = self.heads[i](x)
      x_i = F.interpolate(x_i, size=self.input_sz, mode="bilinear")
      results.append(x_i)

    return results


class SegmentationNet10a(VGGNet):
  cfg = [(64, 1), (128, 1), ('M', None), (256, 1), (256, 1),
         (512, 2), (512, 2)]  # 30x30 recep field

  def __init__(self, config):
    super(SegmentationNet10a, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    self.trunk = SegmentationNet10aTrunk(config, cfg=SegmentationNet10a.cfg)
    self.head = SegmentationNet10aHead(config, output_k=config.output_k,
                                       cfg=SegmentationNet10a.cfg)

    self._initialize_weights()

  def forward(self, x):
    x = self.trunk(x)
    x = self.head(x)
    return x
74/2:
import torch.nn as nn
import torch.nn.functional as F


class VGGTrunk(nn.Module):
  def __init__(self):
    super(VGGTrunk, self).__init__()

  def _make_layers(self, batch_norm=True):
    layers = []
    in_channels = self.in_channels
    for tup in self.cfg:
      assert (len(tup) == 2)

      out, dilation = tup
      sz = self.conv_size
      stride = 1
      pad = self.pad  # to avoid shrinking

      if out == 'M':
        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
      elif out == 'A':
        layers += [nn.AvgPool2d(kernel_size=2, stride=2)]
      else:
        conv2d = nn.Conv2d(in_channels, out, kernel_size=sz,
                           stride=stride, padding=pad,
                           dilation=dilation, bias=False)
        if batch_norm:
          layers += [conv2d, nn.BatchNorm2d(out,
                                            track_running_stats=self.batchnorm_track),
                     nn.ReLU(inplace=True)]
        else:
          layers += [conv2d, nn.ReLU(inplace=True)]
        in_channels = out

    return nn.Sequential(*layers)


class VGGNet(nn.Module):
  def __init__(self):
    super(VGGNet, self).__init__()

  def _initialize_weights(self, mode='fan_in'):
    for m in self.modules():
      if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode=mode, nonlinearity='relu')
        if m.bias is not None:
          m.bias.data.zero_()
      elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
        assert (m.track_running_stats == self.batchnorm_track)
        m.weight.data.fill_(1)
        m.bias.data.zero_()
      elif isinstance(m, nn.Linear):
        m.weight.data.normal_(0, 0.01)
        m.bias.data.zero_()
        

__all__ = ["SegmentationNet10a"]


# From first iteration of code, based on VGG11:
# https://github.com/xu-ji/unsup/blob/master/mutual_information/networks
# /vggseg.py

class SegmentationNet10aTrunk(VGGTrunk):
  def __init__(self, config, cfg):
    super(SegmentationNet10aTrunk, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    assert (config.input_sz % 2 == 0)

    self.conv_size = 3
    self.pad = 1
    self.cfg = cfg
    self.in_channels = config.in_channels if hasattr(config, 'in_channels') \
      else 3

    self.features = self._make_layers()

  def forward(self, x):
    x = self.features(x)  # do not flatten
    return x


class SegmentationNet10aHead(nn.Module):
  def __init__(self, config, output_k, cfg):
    super(SegmentationNet10aHead, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    self.cfg = cfg
    num_features = self.cfg[-1][0]

    self.num_sub_heads = config.num_sub_heads

    self.heads = nn.ModuleList([nn.Sequential(
      nn.Conv2d(num_features, output_k, kernel_size=1,
                stride=1, dilation=1, padding=1, bias=False),
      nn.Softmax2d()) for _ in xrange(self.num_sub_heads)])

    self.input_sz = config.input_sz

  def forward(self, x):
    results = []
    for i in xrange(self.num_sub_heads):
      x_i = self.heads[i](x)
      x_i = F.interpolate(x_i, size=self.input_sz, mode="bilinear")
      results.append(x_i)

    return results


class SegmentationNet10a(VGGNet):
  cfg = [(64, 1), (128, 1), ('M', None), (256, 1), (256, 1),
         (512, 2), (512, 2)]  # 30x30 recep field

  def __init__(self, config):
    super(SegmentationNet10a, self).__init__()

    self.batchnorm_track = config.batchnorm_track

    self.trunk = SegmentationNet10aTrunk(config, cfg=SegmentationNet10a.cfg)
    self.head = SegmentationNet10aHead(config, output_k=config.output_k,
                                       cfg=SegmentationNet10a.cfg)

    self._initialize_weights()

  def forward(self, x):
    x = self.trunk(x)
    x = self.head(x)
    return x
74/3: from IIC.code.archs import segmentation
74/4: from IIC.code_.archs import segmentation
74/5: import code
74/6:
import code
import code.archs
75/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
75/2:
import code
import code.archs
76/1:
import code
import code.archs
76/2:
import IIC.code
import code.archs
77/1: from IIC.code.archs import segmentation
77/2: from IIC.code.archs import segmentation
78/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
78/2: from IIC.code.archs import segmentation
78/3: from IIC.src.archs import segmentation
78/4: from IIC.src.archs import cluster
78/5: from IIC.src.archs.cluster import SegmentationNet10a
78/6: from IIC.src.archs.cluster.net10a import SegmentationNet10a
78/7: from IIC.src.archs.cluster import ClusterNet6c
78/8:
from IIC.src.archs.cluster import ClusterNet6c

net = ClusterNet6c()
print(net)
78/9:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config = namedtuple({
})
net = ClusterNet6c(config)
print(net)
78/10:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config = namedtuple('Config', 'a')
net = ClusterNet6c(config)
print(net)
78/11:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config = namedtuple('Config', 'batchnorm_track')
net = ClusterNet6c(config)
print(net)
78/12:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config = namedtuple('Config', 'batchnorm_track num_sub_heads')
net = ClusterNet6c(config)
print(net)
78/13:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config = namedtuple('Config', 'batchnorm_track num_sub_heads input_sz')
net = ClusterNet6c(config)
print(net)
78/14:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

Config = namedtuple('Config', 'batchnorm_track num_sub_heads input_sz')
config = Config(
    batchnorm_track=True,
    num_sub_heads=5,
    input_sz=1024,
    
)
net = ClusterNet6c(config)
print(net)
78/15:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

Config = namedtuple('Config', 'batchnorm_track num_sub_heads input_sz')
config = Config(
    batchnorm_track=True,
    num_sub_heads=5,
    input_sz=64,
    
)
net = ClusterNet6c(config)
print(net)
78/16:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

Config = namedtuple('Config', 'batchnorm_track num_sub_heads input_sz')
config = Config(
    batchnorm_track=True,
    num_sub_heads=5,
    input_sz=64,
    output_k=10
)
net = ClusterNet6c(config)
print(net)
78/17:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

Config = namedtuple('Config', 'batchnorm_track num_sub_heads input_sz output_k')
config = Config(
    batchnorm_track=True,
    num_sub_heads=5,
    input_sz=64,
    output_k=10
)
net = ClusterNet6c(config)
print(net)
78/18:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
78/19:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
78/20:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 32,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
78/21:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
78/22:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(type(net))
78/23:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
78/24:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from src.data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/4:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/5:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
79/6:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
80/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
80/2:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
80/3:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
80/4:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')
from data_sim.gen_data import ClusterDataset
from tifffile import imshow
80/5:
cluster1 = {
    'x': 250,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

cluster2 = {
    'x': 10000,
    'y': 500,
    'scale': 1000,
    'n_points': 100
}

clusters = [cluster1, cluster2]
cd = ClusterDataset(clusters)

df = cd.df
plt.scatter(df['x'], df['y'], c=df['clusterID'])
80/6:
def norm_zero_one(s):
    return (s - s.min()) / (s.max() - s.min())
80/7:
from functools import partial
from scipy.spatial.distance import cdist

coords = df[['x', 'y']].to_numpy()
max_distance = (df['x'].max() - df['x'].min()) / 4


def temperature(points, target_point):
    target_point = target_point[np.newaxis]
    distances = cdist(points, target_point)
    distances = list(filter(lambda d: d < max_distance, distances))
    temp = sum(distances)
    return temp

func = partial(temperature, coords)

df['temp'] = np.apply_along_axis(func, arr=coords, axis=1)

df['temp'] = norm_zero_one(df['temp'])
scatter_plot = df.plot.scatter('x', 'y', c='temp')
plt.xlabel('x (nm)')
plt.ylabel('y (nm)')
scatter_plot.set_aspect('equal')
80/8:
# def gkern(l=24, sig=1.):
#     """\
#     creates gaussian kernel with side length `l` and a sigma of `sig`
#     """
#     ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)
#     gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))
#     kernel = np.outer(gauss, gauss)
#     return kernel / np.sum(kernel)
from scipy.ndimage.filters import gaussian_filter

def coord_to_corner_voxel(voxel_size, coords):
    center_voxel = coords // voxel_size
    return center_voxel.astype(int)

def raster_img(df, voxel_size, img_shape):
    img = np.zeros(img_shape)
    for i in range(df.shape[0]):
        point = dict(df.iloc[i])
        coords = np.array([point['y'], point['x']])
        x, y = coord_to_corner_voxel(voxel_size, coords)
        if x >= img.shape[1] or y >= img.shape[0]:
            print(f'{x}, {y} is out of bounds')
            continue
        img[x, y] += point['temp']
    img = (img / img.max())

    blurred = gaussian_filter(img, sigma=7)
    return blurred
IMG_DIM_PIXELS = (240, 240)    
# kernel = gkern()

img = raster_img(df, 90, IMG_DIM_PIXELS)
imshow(img)
plt.show()
80/9:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
80/10:
from IIC.src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
80/11:
from IIC.iic_src.archs.cluster import ClusterNet6c
from collections import namedtuple

config_dict = {
    'in_channels': 1,
    'batchnorm_track': True,
    'num_sub_heads': 5,
    'input_sz': 64,
    'output_k': 10
}
Config = namedtuple('Config', ' '.join(list(config_dict.keys())))
config = Config(**config_dict)
net = ClusterNet6c(config)
print(net)
80/12:
#!/usr/bin/python
# -*- coding: utf-8 -*-

for e_i in xrange(next_epoch, config.num_epochs):
    print 'Starting e_i: %d %s' % (e_i, datetime.now())
    sys.stdout.flush()

    iterators = (d for d in dataloaders)

    b_i = 0
    if e_i in config.lr_schedule:
        optimiser = update_lr(optimiser, lr_mult=config.lr_mult)

    avg_loss = 0.
    avg_loss_no_lamb = 0.
    avg_loss_count = 0

    for tup in itertools.izip(*iterators):
        net.module.zero_grad()

        if not config.no_sobel:

      # one less because this is before sobel

            pre_channels = config.in_channels - 1
        else:
            pre_channels = config.in_channels

        all_img1 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_img2 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_affine2_to_1 = torch.zeros(config.batch_sz, 2,
                3).to(torch.float32).cuda()
        all_mask_img1 = torch.zeros(config.batch_sz, config.input_sz,
                                    config.input_sz).to(torch.float32).cuda()

        curr_batch_sz = tup[0][0].shape[0]
        for d_i in xrange(config.num_dataloaders):
            (img1, img2, affine2_to_1, mask_img1) = tup[d_i]
            assert img1.shape[0] == curr_batch_sz

            actual_batch_start = d_i * curr_batch_sz
            actual_batch_end = actual_batch_start + curr_batch_sz

            all_img1[actual_batch_start:actual_batch_end, :, :, :] = \
                img1
            all_img2[actual_batch_start:actual_batch_end, :, :, :] = \
                img2
            all_affine2_to_1[actual_batch_start:actual_batch_end, :, :
                             ] = affine2_to_1
            all_mask_img1[actual_batch_start:actual_batch_end, :, :] = \
                mask_img1

        if not curr_batch_sz == config.dataloader_batch_sz and e_i \
            == next_epoch:
            print 'last batch sz %d' % curr_batch_sz

        curr_total_batch_sz = curr_batch_sz * config.num_dataloaders
        all_img1 = all_img1[:curr_total_batch_sz, :, :, :]
        all_img2 = all_img2[:curr_total_batch_sz, :, :, :]
        all_affine2_to_1 = all_affine2_to_1[:curr_total_batch_sz, :, :]
        all_mask_img1 = all_mask_img1[:curr_total_batch_sz, :, :]

        if not config.no_sobel:
            all_img1 = sobel_process(all_img1, config.include_rgb,
                    using_IR=config.using_IR)
            all_img2 = sobel_process(all_img2, config.include_rgb,
                    using_IR=config.using_IR)

        x1_outs = net(all_img1)
        x2_outs = net(all_img2)

        avg_loss_batch = None  # avg over the heads
        avg_loss_no_lamb_batch = None
        for i in xrange(config.num_sub_heads):
            (loss, loss_no_lamb) = loss_fn(
                x1_outs[i],
                x2_outs[i],
                all_affine2_to_1=all_affine2_to_1,
                all_mask_img1=all_mask_img1,
                lamb=config.lamb,
                half_T_side_dense=config.half_T_side_dense,
                half_T_side_sparse_min=config.half_T_side_sparse_min,
                half_T_side_sparse_max=config.half_T_side_sparse_max,
                )

            if avg_loss_batch is None:
                avg_loss_batch = loss
                avg_loss_no_lamb_batch = loss_no_lamb
            else:
                avg_loss_batch += loss
                avg_loss_no_lamb_batch += loss_no_lamb

        avg_loss_batch /= config.num_sub_heads
        avg_loss_no_lamb_batch /= config.num_sub_heads

        if b_i % 100 == 0 or e_i == next_epoch:
            print 'Model ind %d epoch %d batch: %d avg loss %f avg loss no lamb %f time %s' \
                % (
                config.model_ind,
                e_i,
                b_i,
                avg_loss_batch.item(),
                avg_loss_no_lamb_batch.item(),
                datetime.now(),
                )
            sys.stdout.flush()

        if not np.isfinite(float(avg_loss_batch.data)):
            print 'Loss is not finite... %s:' % str(avg_loss_batch)
            exit(1)

        avg_loss += avg_loss_batch.item()
        avg_loss_no_lamb += avg_loss_no_lamb_batch.item()
        avg_loss_count += 1

        avg_loss_batch.backward()

        optimiser.step()

        b_i += 1
        if b_i == 2 and config.test_code:
            break
80/13:
#!/usr/bin/python
# -*- coding: utf-8 -*-

for e_i in xrange(next_epoch, config.num_epochs):
    print 'Starting e_i: %d %s' % (e_i, datetime.now())
    sys.stdout.flush()

    iterators = (d for d in dataloaders)

    b_i = 0
    if e_i in config.lr_schedule:
        optimiser = update_lr(optimiser, lr_mult=config.lr_mult)

    avg_loss = 0.
    avg_loss_no_lamb = 0.
    avg_loss_count = 0

    for tup in itertools.izip(*iterators):
        net.module.zero_grad()

        if not config.no_sobel:

      # one less because this is before sobel

            pre_channels = config.in_channels - 1
        else:
            pre_channels = config.in_channels

        all_img1 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_img2 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_affine2_to_1 = torch.zeros(config.batch_sz, 2,
                3).to(torch.float32).cuda()
        all_mask_img1 = torch.zeros(config.batch_sz, config.input_sz,
                                    config.input_sz).to(torch.float32).cuda()

        curr_batch_sz = tup[0][0].shape[0]
        for d_i in xrange(config.num_dataloaders):
            (img1, img2, affine2_to_1, mask_img1) = tup[d_i]
            assert img1.shape[0] == curr_batch_sz

            actual_batch_start = d_i * curr_batch_sz
            actual_batch_end = actual_batch_start + curr_batch_sz

            all_img1[actual_batch_start:actual_batch_end, :, :, :] = \
                img1
            all_img2[actual_batch_start:actual_batch_end, :, :, :] = \
                img2
            all_affine2_to_1[actual_batch_start:actual_batch_end, :, :
                             ] = affine2_to_1
            all_mask_img1[actual_batch_start:actual_batch_end, :, :] = \
                mask_img1

        if not curr_batch_sz == config.dataloader_batch_sz and e_i \
            == next_epoch:
            print('last batch sz %d' % curr_batch_sz)

        curr_total_batch_sz = curr_batch_sz * config.num_dataloaders
        all_img1 = all_img1[:curr_total_batch_sz, :, :, :]
        all_img2 = all_img2[:curr_total_batch_sz, :, :, :]
        all_affine2_to_1 = all_affine2_to_1[:curr_total_batch_sz, :, :]
        all_mask_img1 = all_mask_img1[:curr_total_batch_sz, :, :]

        if not config.no_sobel:
            all_img1 = sobel_process(all_img1, config.include_rgb,
                    using_IR=config.using_IR)
            all_img2 = sobel_process(all_img2, config.include_rgb,
                    using_IR=config.using_IR)

        x1_outs = net(all_img1)
        x2_outs = net(all_img2)

        avg_loss_batch = None  # avg over the heads
        avg_loss_no_lamb_batch = None
        for i in xrange(config.num_sub_heads):
            (loss, loss_no_lamb) = loss_fn(
                x1_outs[i],
                x2_outs[i],
                all_affine2_to_1=all_affine2_to_1,
                all_mask_img1=all_mask_img1,
                lamb=config.lamb,
                half_T_side_dense=config.half_T_side_dense,
                half_T_side_sparse_min=config.half_T_side_sparse_min,
                half_T_side_sparse_max=config.half_T_side_sparse_max,
                )

            if avg_loss_batch is None:
                avg_loss_batch = loss
                avg_loss_no_lamb_batch = loss_no_lamb
            else:
                avg_loss_batch += loss
                avg_loss_no_lamb_batch += loss_no_lamb

        avg_loss_batch /= config.num_sub_heads
        avg_loss_no_lamb_batch /= config.num_sub_heads

        if b_i % 100 == 0 or e_i == next_epoch:
            print 'Model ind %d epoch %d batch: %d avg loss %f avg loss no lamb %f time %s' \
                % (
                config.model_ind,
                e_i,
                b_i,
                avg_loss_batch.item(),
                avg_loss_no_lamb_batch.item(),
                datetime.now(),
                )
            sys.stdout.flush()

        if not np.isfinite(float(avg_loss_batch.data)):
            print 'Loss is not finite... %s:' % str(avg_loss_batch)
            exit(1)

        avg_loss += avg_loss_batch.item()
        avg_loss_no_lamb += avg_loss_no_lamb_batch.item()
        avg_loss_count += 1

        avg_loss_batch.backward()

        optimiser.step()

        b_i += 1
        if b_i == 2 and config.test_code:
            break
80/14:
#!/usr/bin/python
# -*- coding: utf-8 -*-

for e_i in xrange(next_epoch, config.num_epochs):
    print('Starting e_i: %d %s' % (e_i, datetime.now()))
    sys.stdout.flush()

    iterators = (d for d in dataloaders)

    b_i = 0
    if e_i in config.lr_schedule:
        optimiser = update_lr(optimiser, lr_mult=config.lr_mult)

    avg_loss = 0.
    avg_loss_no_lamb = 0.
    avg_loss_count = 0

    for tup in itertools.izip(*iterators):
        net.module.zero_grad()

        if not config.no_sobel:

      # one less because this is before sobel

            pre_channels = config.in_channels - 1
        else:
            pre_channels = config.in_channels

        all_img1 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_img2 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_affine2_to_1 = torch.zeros(config.batch_sz, 2,
                3).to(torch.float32).cuda()
        all_mask_img1 = torch.zeros(config.batch_sz, config.input_sz,
                                    config.input_sz).to(torch.float32).cuda()

        curr_batch_sz = tup[0][0].shape[0]
        for d_i in xrange(config.num_dataloaders):
            (img1, img2, affine2_to_1, mask_img1) = tup[d_i]
            assert img1.shape[0] == curr_batch_sz

            actual_batch_start = d_i * curr_batch_sz
            actual_batch_end = actual_batch_start + curr_batch_sz

            all_img1[actual_batch_start:actual_batch_end, :, :, :] = \
                img1
            all_img2[actual_batch_start:actual_batch_end, :, :, :] = \
                img2
            all_affine2_to_1[actual_batch_start:actual_batch_end, :, :
                             ] = affine2_to_1
            all_mask_img1[actual_batch_start:actual_batch_end, :, :] = \
                mask_img1

        if not curr_batch_sz == config.dataloader_batch_sz and e_i \
            == next_epoch:
            print('last batch sz %d' % curr_batch_sz)

        curr_total_batch_sz = curr_batch_sz * config.num_dataloaders
        all_img1 = all_img1[:curr_total_batch_sz, :, :, :]
        all_img2 = all_img2[:curr_total_batch_sz, :, :, :]
        all_affine2_to_1 = all_affine2_to_1[:curr_total_batch_sz, :, :]
        all_mask_img1 = all_mask_img1[:curr_total_batch_sz, :, :]

        if not config.no_sobel:
            all_img1 = sobel_process(all_img1, config.include_rgb,
                    using_IR=config.using_IR)
            all_img2 = sobel_process(all_img2, config.include_rgb,
                    using_IR=config.using_IR)

        x1_outs = net(all_img1)
        x2_outs = net(all_img2)

        avg_loss_batch = None  # avg over the heads
        avg_loss_no_lamb_batch = None
        for i in xrange(config.num_sub_heads):
            (loss, loss_no_lamb) = loss_fn(
                x1_outs[i],
                x2_outs[i],
                all_affine2_to_1=all_affine2_to_1,
                all_mask_img1=all_mask_img1,
                lamb=config.lamb,
                half_T_side_dense=config.half_T_side_dense,
                half_T_side_sparse_min=config.half_T_side_sparse_min,
                half_T_side_sparse_max=config.half_T_side_sparse_max,
                )

            if avg_loss_batch is None:
                avg_loss_batch = loss
                avg_loss_no_lamb_batch = loss_no_lamb
            else:
                avg_loss_batch += loss
                avg_loss_no_lamb_batch += loss_no_lamb

        avg_loss_batch /= config.num_sub_heads
        avg_loss_no_lamb_batch /= config.num_sub_heads

        if b_i % 100 == 0 or e_i == next_epoch:
            print ('Model ind %d epoch %d batch: %d avg loss %f avg loss no lamb %f time %s' \
                % (
                config.model_ind,
                e_i,
                b_i,
                avg_loss_batch.item(),
                avg_loss_no_lamb_batch.item(),
                datetime.now(),
                ))
            sys.stdout.flush()

        if not np.isfinite(float(avg_loss_batch.data)):
            print('Loss is not finite... %s:' % str(avg_loss_batch))
            exit(1)

        avg_loss += avg_loss_batch.item()
        avg_loss_no_lamb += avg_loss_no_lamb_batch.item()
        avg_loss_count += 1

        avg_loss_batch.backward()

        optimiser.step()

        b_i += 1
        if b_i == 2 and config.test_code:
            break
80/15:
#!/usr/bin/python
# -*- coding: utf-8 -*-

for e_i in range(next_epoch, config.num_epochs):
    print('Starting e_i: %d %s' % (e_i, datetime.now()))
    sys.stdout.flush()

    iterators = (d for d in dataloaders)

    b_i = 0
    if e_i in config.lr_schedule:
        optimiser = update_lr(optimiser, lr_mult=config.lr_mult)

    avg_loss = 0.
    avg_loss_no_lamb = 0.
    avg_loss_count = 0

    for tup in itertools.izip(*iterators):
        net.module.zero_grad()

        if not config.no_sobel:

      # one less because this is before sobel

            pre_channels = config.in_channels - 1
        else:
            pre_channels = config.in_channels

        all_img1 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_img2 = torch.zeros(config.batch_sz, pre_channels,
                               config.input_sz,
                               config.input_sz).to(torch.float32).cuda()
        all_affine2_to_1 = torch.zeros(config.batch_sz, 2,
                3).to(torch.float32).cuda()
        all_mask_img1 = torch.zeros(config.batch_sz, config.input_sz,
                                    config.input_sz).to(torch.float32).cuda()

        curr_batch_sz = tup[0][0].shape[0]
        for d_i in xrange(config.num_dataloaders):
            (img1, img2, affine2_to_1, mask_img1) = tup[d_i]
            assert img1.shape[0] == curr_batch_sz

            actual_batch_start = d_i * curr_batch_sz
            actual_batch_end = actual_batch_start + curr_batch_sz

            all_img1[actual_batch_start:actual_batch_end, :, :, :] = \
                img1
            all_img2[actual_batch_start:actual_batch_end, :, :, :] = \
                img2
            all_affine2_to_1[actual_batch_start:actual_batch_end, :, :
                             ] = affine2_to_1
            all_mask_img1[actual_batch_start:actual_batch_end, :, :] = \
                mask_img1

        if not curr_batch_sz == config.dataloader_batch_sz and e_i \
            == next_epoch:
            print('last batch sz %d' % curr_batch_sz)

        curr_total_batch_sz = curr_batch_sz * config.num_dataloaders
        all_img1 = all_img1[:curr_total_batch_sz, :, :, :]
        all_img2 = all_img2[:curr_total_batch_sz, :, :, :]
        all_affine2_to_1 = all_affine2_to_1[:curr_total_batch_sz, :, :]
        all_mask_img1 = all_mask_img1[:curr_total_batch_sz, :, :]

        if not config.no_sobel:
            all_img1 = sobel_process(all_img1, config.include_rgb,
                    using_IR=config.using_IR)
            all_img2 = sobel_process(all_img2, config.include_rgb,
                    using_IR=config.using_IR)

        x1_outs = net(all_img1)
        x2_outs = net(all_img2)

        avg_loss_batch = None  # avg over the heads
        avg_loss_no_lamb_batch = None
        for i in xrange(config.num_sub_heads):
            (loss, loss_no_lamb) = loss_fn(
                x1_outs[i],
                x2_outs[i],
                all_affine2_to_1=all_affine2_to_1,
                all_mask_img1=all_mask_img1,
                lamb=config.lamb,
                half_T_side_dense=config.half_T_side_dense,
                half_T_side_sparse_min=config.half_T_side_sparse_min,
                half_T_side_sparse_max=config.half_T_side